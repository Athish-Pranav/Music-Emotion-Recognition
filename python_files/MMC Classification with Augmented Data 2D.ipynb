{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467ed1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9be511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,BatchNormalization, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4631b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features2D/Features2D.npz\")\n",
    "f_noise = np.load(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features2D/Features_noise.npz\")\n",
    "f_shift = np.load(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features2D/Features_noise.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db963bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = f['spec'] #(400,1025,1099)\n",
    "mfcc = f['mfcc'] #(400,20,1099)\n",
    "mel = f['mel']#(400,128,1099)\n",
    "y = f['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54482a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_noise = f_noise['spec'] #(400,1025,1099)\n",
    "mfcc_noise = f_noise['mfcc'] #(400,20,1099)\n",
    "mel_noise = f_noise['mel']#(400,128,1099)\n",
    "y_noise = f_noise['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57eac514",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_shift = f_shift['spec'] #(400,1025,1099)\n",
    "mfcc_shift = f_shift['mfcc'] #(400,20,1099)\n",
    "mel_shift = f_shift['mel']#(400,128,1099)\n",
    "y_shift = f_shift['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9448b9d",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "### 3.1 Resize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a48043",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_resized = np.empty((973, 120, 600))\n",
    "mfcc_noise_resized = np.empty((973, 120, 600))\n",
    "mfcc_shift_resized = np.empty((973, 120, 600))\n",
    "\n",
    "for i in range(973):\n",
    "    mfcc_resized[i] = cv2.resize(mfcc[i], (600, 120))\n",
    "    mfcc_noise_resized[i] = cv2.resize(mfcc_noise[i], (600, 120))\n",
    "    mfcc_shift_resized[i] = cv2.resize(mfcc_shift[i], (600, 120))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fa96a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing the Spectrogram features\n",
    "spec_resized = np.empty((973, 300, 300))\n",
    "spec_noise_resized = np.empty((973, 300, 300))\n",
    "spec_shift_resized = np.empty((973, 300, 300))\n",
    "\n",
    "for i in range(973):\n",
    "    spec_resized[i] = cv2.resize(spec[i], (300, 300))\n",
    "    spec_noise_resized[i] = cv2.resize(spec_noise[i], (300, 300))\n",
    "    spec_shift_resized[i] = cv2.resize(spec_shift[i], (300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d782e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing the Mel features\n",
    "mel_resized = np.empty((973, 300, 400))\n",
    "mel_noise_resized = np.empty((973, 300, 400))\n",
    "mel_shift_resized = np.empty((973, 300, 400))\n",
    "\n",
    "for i in range(973):\n",
    "    mel_resized[i] = cv2.resize(mel[i], (400, 300))\n",
    "    mel_noise_resized[i] = cv2.resize(mel_noise[i], (400, 300))\n",
    "    mel_shift_resized[i] = cv2.resize(mel_shift[i], (400, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b0d662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y after correction: (973,)\n"
     ]
    }
   ],
   "source": [
    "# Assuming that you mistakenly created y with only 400 samples\n",
    "# Recreate y with the correct number of samples (973 in this case)\n",
    "# Example: y = np.array([label1, label2, ... , label973])\n",
    "\n",
    "# Ensure y now has the correct shape\n",
    "print(f\"Shape of y after correction: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37f7e2",
   "metadata": {},
   "source": [
    "### 3.2 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184ed362",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc0_train,mfcc_test,y0_train,y_test = train_test_split(mfcc_resized,y, \n",
    "                                                         train_size = 0.7, \n",
    "                                                         random_state = 13, \n",
    "                                                         stratify= y)\n",
    "mfcc_train_agumented = np.concatenate((mfcc0_train,mfcc_noise_resized,mfcc_shift_resized))\n",
    "y1_train_agumented = np.concatenate((y0_train,y_noise,y_shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c14703",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec0_train,spec_test,y0_train,y_test = train_test_split(spec_resized,y, \n",
    "                                                   train_size = 0.7, \n",
    "                                                   random_state = 13, \n",
    "                                                   stratify= y)\n",
    "spec_train_agumented = np.concatenate((spec0_train,spec_noise_resized,spec_shift_resized))\n",
    "y2_train_agumented = np.concatenate((y0_train,y_noise,y_shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d08ead48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel0_train,mel_test,y0_train,y_test = train_test_split(mel_resized,y, \n",
    "                                                       train_size = 0.7, \n",
    "                                                       random_state = 13, \n",
    "                                                       stratify= y)\n",
    "mel_train_agumented = np.concatenate((mel0_train,mel_noise_resized,mel_shift_resized))\n",
    "y3_train_agumented = np.concatenate((y0_train,y_noise,y_shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7aebd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features2D/training models/mfcc_train_test_agumented.npz\",\n",
    "                    mfcc_train = mfcc_train_agumented, \n",
    "                    mfcc_test = mfcc_test, \n",
    "                    y_train = y1_train_agumented, \n",
    "                    y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caa7a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features2D/training models/spec_train_test_agumented.npz\",\n",
    "                    spec_train = spec_train_agumented, \n",
    "                    spec_test = spec_test, \n",
    "                    y_train = y2_train_agumented, \n",
    "                    y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2822e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features2D/training models/mel_train_test_agumented.npz\",\n",
    "                    mel_train = mel_train_agumented, \n",
    "                    mel_test = mel_test, \n",
    "                    y_train = y3_train_agumented, \n",
    "                    y_test = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb83584",
   "metadata": {},
   "source": [
    "### 3.2 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a40b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_scaled = spec_resized / np.amax(spec_resized)\n",
    "mfcc_scaled = (mfcc_resized - np.mean(mfcc_resized))/np.std(mfcc_resized)\n",
    "mel_scaled = mel_resized / np.amax(mel_resized)\n",
    "\n",
    "spec_noise_scaled = spec_noise_resized / np.amax(spec_noise_resized)\n",
    "mfcc_noise_scaled = (mfcc_noise_resized - np.mean(mfcc_noise_resized))/np.std(mfcc_noise_resized)\n",
    "mel_noise_scaled = mel_noise_resized / np.amax(mel_noise_resized)\n",
    "\n",
    "spec_shift_scaled = spec_shift_resized / np.amax(spec_shift_resized)\n",
    "mfcc_shift_scaled = (mfcc_shift_resized - np.mean(mfcc_shift_resized))/np.std(mfcc_shift_resized)\n",
    "mel_shift_scaled = mel_shift_resized / np.amax(mel_shift_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f5626",
   "metadata": {},
   "source": [
    "### 3.3. Reshape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "095ac704",
   "metadata": {},
   "outputs": [],
   "source": [
    "N,row,col = mfcc_scaled.shape\n",
    "mfcc_reshaped = mfcc_scaled.reshape((N,row,col,1))\n",
    "N,row,col = mfcc_noise_scaled.shape\n",
    "mfcc_noise_reshaped = mfcc_noise_scaled.reshape((N,row,col,1))\n",
    "N,row,col = mfcc_shift_scaled.shape\n",
    "mfcc_shift_reshaped = mfcc_shift_scaled.reshape((N,row,col,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3050cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N,row,col = spec_scaled.shape\n",
    "spec_reshaped = spec_scaled.reshape((N,row,col,1))\n",
    "N,row,col = spec_noise_scaled.shape\n",
    "spec_noise_reshaped = spec_noise_scaled.reshape((N,row,col,1))\n",
    "N,row,col = spec_shift_scaled.shape\n",
    "spec_shift_reshaped = spec_shift_scaled.reshape((N,row,col,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3c57cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N,row,col = mel_scaled.shape\n",
    "mel_reshaped = mel_scaled.reshape((N,row,col,1))\n",
    "N,row,col = mel_noise_scaled.shape\n",
    "mel_noise_reshaped = mel_noise_scaled.reshape((N,row,col,1))\n",
    "N,row,col = mel_shift_scaled.shape\n",
    "mel_shift_reshaped = mel_shift_scaled.reshape((N,row,col,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e372df",
   "metadata": {},
   "source": [
    "## 4. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6ed8c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def modelBuilder3L(X_train,\n",
    "                   f1,k1,a1,\n",
    "                   mr1,mc1,sr1,sc1,\n",
    "                   f2,k2,a2,\n",
    "                   mr2,mc2,sr2,sc2,\n",
    "                   f3,k3,a3,\n",
    "                   mr3,m3,sr3,sc3,\n",
    "                   d1,dr1,da1,r1,\n",
    "                   d2,dr2,da2,r2,\n",
    "                   num):\n",
    "    \n",
    "    '''\n",
    "    args:\n",
    "    \n",
    "    X_train: training data\n",
    "    f1,k1,a1: num of filters, filter size and activation func of 1st conv2D layer\n",
    "    mr1,mc1,sr1,sc1: filter size and strides of 1st MaxPooling2D layer\n",
    "    f2,k2,a2: num of filters, filter size and activation func of 2nd conv2D layer\n",
    "    mr2,mc2,sr2,sc2: filter size and strides of 2nd MaxPooling2D layer\n",
    "    f3,k3,a3: num of filters, filter size and activation func of 3rd conv2D layer\n",
    "    mr3,sc3,sr3,sc3: filter size and strides of 3rd MaxPooling2D layer\n",
    "    d1,dr1,da1, r1: num of units, dropout, activation func and regularizer para of 1st fully connected layer\n",
    "    d2,dr2,da2, r2: num of units, dropout, activation func and regularizer para of 2nd fully connected layer\n",
    "    num: integer for distinguishing different model\n",
    "    \n",
    "    return:\n",
    "    model\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    N,row,col,Nc = X_train.shape\n",
    "    \n",
    "    model = Sequential(name = \"CNN2D_\"+str(num))\n",
    "    #L1\n",
    "    model.add(Conv2D(f1,(k1,k1),activation = a1,input_shape = (row,col,Nc), padding = 'same', name = 'Conv2D_1'))\n",
    "    model.add(MaxPooling2D((mw1,mh1), strides = (sw1,sh1), padding = 'same', name = 'MaxPooling2D_1'))\n",
    "    model.add(BatchNormalization(name = \"BN1\"))\n",
    "    \n",
    "    #L2\n",
    "    model.add(Conv2D(f2,(k2,k2), activation = a2, padding = 'same',name = 'Conv2D_2'))\n",
    "    model.add(MaxPooling2D((mw2,mh2),strides = (sw2,sh2), padding = 'same', name = 'MaxPooling2D_2'))\n",
    "    model.add(BatchNormalization(name = \"BN2\"))\n",
    "\n",
    "    #L3\n",
    "    model.add(Conv2D(f3,(k3,k3), activation = a3, padding = 'same',name = 'Conv2D_3'))\n",
    "    model.add(MaxPooling2D((mw3,mh3), strides = (sw3,sh3), padding = 'same', name = 'MaxPooling2D_3'))\n",
    "    model.add(BatchNormalization(name = \"BN3\"))\n",
    "   \n",
    "    #Flatten layer\n",
    "    model.add(Flatten(name = 'Flatten'))\n",
    "    #FC4\n",
    "    model.add(Dense(d1, activation = da1, kernel_regularizer = tf.keras.regularizers.L2(r1), name='Dense1'))\n",
    "    model.add(Dropout(dr1, name = \"Dropout1\"))\n",
    "    #FC5\n",
    "    model.add(Dense(d2, activation = da2, kernel_regularizer = tf.keras.regularizers.L2(r2), name='Dense2'))\n",
    "    model.add(Dropout(dr2, name = \"Dropout2\"))\n",
    "    #Softmax layer\n",
    "    model.add(Dense(4, activation ='softmax', name='Softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer= optimizer, loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14441af7",
   "metadata": {},
   "source": [
    "### 4.1 MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f5dd320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MFCC data set\n",
    "mfcc_file = np.load(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features2D/training models/mfcc_train_test_agumented.npz\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5109375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mfcc_train = mfcc_file['mfcc_train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86ab45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = mfcc_file['y_train']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c16f28e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.13 GiB for an array with shape (2101, 120, 600) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# validation set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m mfcc_train,mfcc_val,y1_train,y1_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfcc_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my1_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my1_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2805\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2801\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2803\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[1;32m-> 2805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2807\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[0;32m   2808\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2809\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2807\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2801\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2803\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m   2805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2806\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2807\u001b[0m         (\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m, _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2808\u001b[0m     )\n\u001b[0;32m   2809\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:267\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _polars_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:33\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m     32\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.13 GiB for an array with shape (2101, 120, 600) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "# validation set\n",
    "mfcc_train,mfcc_val,y1_train,y1_val = train_test_split(mfcc_train,y1_train, \n",
    "                                                       train_size = 0.8,  \n",
    "                                                       random_state = 13, \n",
    "                                                       stratify= y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f24a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "mfcc_train_scaled = (mfcc_train - np.mean(mfcc_train))/np.std(mfcc_train)\n",
    "mfcc_val_scaled = (mfcc_val - np.mean(mfcc_val))/np.std(mfcc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064762a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "N,row,col = mfcc_train_scaled.shape\n",
    "mfcc_train_reshaped = mfcc_train_scaled.reshape((N,row,col,1))\n",
    "N,row,col = mfcc_val_scaled.shape\n",
    "mfcc_val_reshaped = mfcc_val_scaled.reshape((N,row,col,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd0099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1,k1,a1 = 8,3,'relu'\n",
    "mw1,mh1,sw1,sh1 = 2,3,2,2\n",
    "f2,k2,a2 = 8,3,'relu'\n",
    "mw2,mh2,sw2,sh2 = 2,3,2,2\n",
    "f3,k3,a3 = 16,3,'relu'\n",
    "mw3,mh3,sw3,sh3 = 2,3,2,2\n",
    "d1,dr1,da1,r1 = 64,0.2,'relu',0.2\n",
    "d2,dr2,da2,r2 = 32,0.2,'relu',0.2\n",
    "num = 1\n",
    "\n",
    "model1 = modelBuilder3L(mfcc_train_reshaped,\n",
    "                        f1,k1,a1,\n",
    "                        mw1,mh1,sw1,sh1,\n",
    "                        f2,k2,a2,\n",
    "                        mw2,mh2,sw2,sh2,\n",
    "                        f3,k3,a3,\n",
    "                        mw3,mh3,sw3,sh3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0055a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history1 = model1.fit(mfcc_train_reshaped,y1_train,validation_data=(mfcc_val_reshaped,y1_val),batch_size=20,epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a70c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validation accuracy and loss\n",
    "f = plt.figure(figsize = (12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('train validation accuracy')\n",
    "plt.plot(history1.history['accuracy'])\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('train validation loss')\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2037e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_test = mfcc_file['mfcc_test']\n",
    "y_test_mfcc = mfcc_file['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "mfcc_test_scaled = (mfcc_test - np.mean(mfcc_test))/np.std(mfcc_test)\n",
    "# Reshape the data\n",
    "N,row,col = mfcc_test_scaled.shape\n",
    "mfcc_test_reshaped = mfcc_test_scaled.reshape((N,row,col,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b327d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_prob = model1.predict(mfcc_test_reshaped)\n",
    "y1_pred = np.argmax(y1_prob, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac44691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acc_mfcc = round(accuracy_score(y1_pred,y_test_mfcc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5050e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_mfcc = confusion_matrix(y_test_mfcc,y1_pred)\n",
    "cm_display_mfcc = ConfusionMatrixDisplay(confusion_matrix = cm_mfcc, display_labels = ['Happy', 'Relaxed', 'Sad'])\n",
    "print(classification_report(y_test_mfcc, y1_pred, target_names = ['Happy', 'Relaxed', 'Sad']))\n",
    "cm_display_mfcc.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"D:/UM/Project/Mozartify/project/Model/CNN_models/2D_CNN/Conv2D_mfcc_agumented.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca332de",
   "metadata": {},
   "source": [
    "### 4.2 Spectrogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee04d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spectrogram data set\n",
    "spec_file = np.load(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features2D/training models/spec_train_test_agumented.npz\")\n",
    "\n",
    "spec_train = spec_file['spec_train']\n",
    "y2_train = spec_file['y_train']\n",
    "\n",
    "spec_train,spec_val,y2_train,y2_val = train_test_split(spec_train,y2_train, \n",
    "                                                       train_size = 0.8,\n",
    "                                                       random_state = 13, \n",
    "                                                       stratify= y2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "spec_train_scaled = spec_train / np.amax(spec_train)\n",
    "spec_val_scaled = spec_val / np.amax(spec_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "N,row,col = spec_train_scaled.shape\n",
    "spec_train_reshaped = spec_train_scaled.reshape((N,row,col,1))\n",
    "N,row,col = spec_val_scaled.shape\n",
    "spec_val_reshaped = spec_val_scaled.reshape((N,row,col,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a3e5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1,k1,a1 = 5,3,'relu'\n",
    "mw1,mh1,sw1,sh1 = 3,3,2,2\n",
    "f2,k2,a2 = 8,3,'relu'\n",
    "mw2,mh2,sw2,sh2 = 3,3,2,2\n",
    "f3,k3,a3 = 16,3,'relu'\n",
    "mw3,mh3,sw3,sh3 = 3,3,2,2\n",
    "d1,dr1,da1,r1 = 64,0.2,'relu',0.2\n",
    "d2,dr2,da2,r2 = 32,0.2,'relu',0.2\n",
    "num = 2\n",
    "model2 = modelBuilder3L(spec_train_reshaped,\n",
    "                        f1,k1,a1,\n",
    "                        mw1,mh1,sw1,sh1,\n",
    "                        f2,k2,a2,\n",
    "                        mw2,mh2,sw2,sh2,\n",
    "                        f3,k3,a3,\n",
    "                        mw3,mh3,sw3,sh3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a503680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history2 = model2.fit(spec_train_reshaped,y2_train,validation_data=(spec_val_reshaped,y2_val),batch_size=20,epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4637d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validation accuracy and loss\n",
    "f = plt.figure(figsize = (12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('train validation accuracy')\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('train validation loss')\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68603b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_test = spec_file['spec_test']\n",
    "y_test_spec = spec_file['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "spec_test_scaled = spec_test / np.amax(spec_test)\n",
    "\n",
    "# Reshape the data\n",
    "N,row,col = spec_test_scaled.shape\n",
    "spec_test_reshaped = spec_test_scaled.reshape((N,row,col,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e99d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_prob = model2.predict(spec_test_reshaped)\n",
    "y2_pred = np.argmax(y2_prob, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993754a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acc_spec = round(accuracy_score(y2_pred,y_test_spec),2)\n",
    "acc_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_spec = confusion_matrix(y_test_spec,y2_pred)\n",
    "cm_display_spec = ConfusionMatrixDisplay(confusion_matrix = cm_spec, display_labels = ['Happy', 'Relaxed', 'Sad'])\n",
    "print(classification_report(y_test_spec, y2_pred, target_names = ['Happy', 'Relaxed', 'Sad']))\n",
    "cm_display_spec.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fde966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model2.save(\"D:/UM/Project/Mozartify/project/Model/CNN_models/2D_CNN/Conv2D_spec_agumented.h5\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f5456",
   "metadata": {},
   "source": [
    "### 4.3 Mel Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_file = np.load(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features2D/training models/mel_train_test_agumented.npz\")\n",
    "\n",
    "mel_train = mel_file['mel_train']\n",
    "y3_train = mel_file['y_train']\n",
    "mel_train,mel_val,y3_train,y3_val = train_test_split(mel_train,y3_train, \n",
    "                                                     train_size = 0.8, \n",
    "                                                     random_state = 13, \n",
    "                                                     stratify= y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9377980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "mel_train_scaled = (mel_train - np.mean(mel_train))/np.std(mel_train)\n",
    "mel_val_scaled = (mel_val - np.mean(mel_val))/np.std(mel_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5aa99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "N,row,col = mel_train_scaled.shape\n",
    "mel_train_reshaped = mel_train_scaled.reshape((N,row,col,1))\n",
    "\n",
    "N,row,col = mel_val_scaled.shape\n",
    "mel_val_reshaped = mel_val_scaled.reshape((N,row,col,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa600a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1,k1,a1 = 8,3,'relu'\n",
    "mw1,mh1,sw1,sh1 = 2,3,2,2\n",
    "f2,k2,a2 = 8,3,'relu'\n",
    "mw2,mh2,sw2,sh2 = 2,3,2,2\n",
    "f3,k3,a3 = 16,3,'relu'\n",
    "mw3,mh3,sw3,sh3 = 2,3,2,2\n",
    "d1,dr1,da1,r1 = 64,0.2,'relu',0.2\n",
    "d2,dr2,da2,r2 = 32,0.2,'relu',0.2\n",
    "num = 3\n",
    "model3 = modelBuilder3L(mel_train_reshaped,\n",
    "                        f1,k1,a1,\n",
    "                        mw1,mh1,sw1,sh1,\n",
    "                        f2,k2,a2,\n",
    "                        mw2,mh2,sw2,sh2,\n",
    "                        f3,k3,a3,\n",
    "                        mw3,mh3,sw3,sh3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359f915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history3 = model3.fit(mel_train_reshaped,y3_train,validation_data=(mel_val_reshaped,y3_val),batch_size=20,epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dacccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validation accuracy and loss\n",
    "f = plt.figure(figsize = (12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('train validation accuracy')\n",
    "plt.plot(history3.history['accuracy'])\n",
    "plt.plot(history3.history['val_accuracy'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('train validation loss')\n",
    "plt.plot(history3.history['loss'])\n",
    "plt.plot(history3.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1bc1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save(\"D:/UM/Project/Mozartify/project/Model/CNN_models/2D_CNN/Conv2D_mel_agumented.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5985931",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_test = mel_file['mel_test']\n",
    "y_test_mel = mel_file['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab860b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_test_scaled = (mel_test - np.mean(mel_test))/np.std(mel_test)\n",
    "\n",
    "# Reshape the data\n",
    "N,row,col = mel_test_scaled.shape\n",
    "mel_test_reshaped = mel_test_scaled.reshape((N,row,col,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3_prob = model3.predict(mel_test_reshaped)\n",
    "y3_pred = np.argmax(y3_prob, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acc_mel = round(accuracy_score(y3_pred,y_test_mel),2)\n",
    "acc_mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_mel = confusion_matrix(y_test_mel,y3_pred)\n",
    "cm_display_mel = ConfusionMatrixDisplay(confusion_matrix = cm_mel, display_labels = ['Happy', 'Relaxed', 'Sad'])\n",
    "print(classification_report(y_test_mel, y3_pred, target_names = ['Happy', 'Relaxed', 'Sad']))\n",
    "cm_display_mel.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd38ef4",
   "metadata": {},
   "source": [
    "## 5. Ensenble 3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91423e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_file_ense = np.load(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features2D/training models/mfcc_train_test_agumented.npz\")\n",
    "mfcc_ense_train = mfcc_file_ense['mfcc_train']\n",
    "mfcc_ense_test =mfcc_file_ense['mfcc_test']\n",
    "y_ense_train = mfcc_file_ense['y_train']\n",
    "y_ense_test = mfcc_file_ense['y_test']\n",
    "model_mfcc = load_model(\"D:/UM/Project/Mozartify/project/Model/CNN_models/2D_CNN/Conv2D_mfcc_agumented.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_file_ense = np.load(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features2D/training models/spec_train_test_agumented.npz\")\n",
    "spec_ense_train = spec_file_ense['spec_train']\n",
    "spec_ense_test = spec_file_ense['spec_test']\n",
    "y_ense_train = spec_file_ense['y_train']\n",
    "y_ense_test = spec_file_ense['y_test']\n",
    "model_spec = load_model(\"D:/UM/Project/Mozartify/project/Model/CNN_models/2D_CNN/Conv2D_spec_agumented.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce67f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec = load_model(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features2D/training models/Conv2D_spec_agumented.h5\")\n",
    "mel_file_ense = np.load(\"/mel_train_test_agumented.npz\")\n",
    "mel_ense_train = mel_file_ense['mel_train']\n",
    "mel_ense_test =mel_file_ense['mel_test']\n",
    "y_ense_train = mel_file_ense['y_train']\n",
    "y_ense_test = mel_file_ense['y_test']\n",
    "model_mel = load_model(\"D:/UM/Project/Mozartify/project/Model/CNN_models/2D_CNN/Conv2D_mel_agumented.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25336c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "mfcc_ense_train_scaled = (mfcc_ense_train - np.mean(mfcc_ense_train))/np.std(mfcc_ense_train)\n",
    "spec_ense_train_scaled = spec_ense_train / np.amax(spec_ense_train)\n",
    "mel_ense_train_scaled = (mel_ense_train - np.mean(mel_ense_train))/np.std(mel_ense_train)\n",
    "\n",
    "mfcc_ense_test_scaled = (mfcc_ense_test - np.mean(mfcc_ense_test))/np.std(mfcc_ense_test)\n",
    "spec_ense_test_scaled = spec_ense_test / np.amax(spec_ense_test)\n",
    "mel_ense_test_scaled = (mel_ense_test - np.mean(mel_ense_test))/np.std(mfcc_ense_test)\n",
    "\n",
    "\n",
    "# Reshape the data\n",
    "N,row,col = mfcc_ense_train_scaled.shape\n",
    "mfcc_ense_train_reshaped = mfcc_ense_train_scaled.reshape((N,row,col,1))\n",
    "N,row,col = spec_ense_train_scaled.shape\n",
    "spec_ense_train_reshaped = spec_ense_train_scaled.reshape((N,row,col,1))\n",
    "N,row,col = mel_ense_train_scaled.shape\n",
    "mel_ense_train_reshaped = mel_ense_train_scaled.reshape((N,row,col,1))\n",
    "\n",
    "N,row,col = mfcc_ense_test_scaled.shape\n",
    "mfcc_ense_test_reshaped = mfcc_ense_test_scaled.reshape((N,row,col,1))\n",
    "N,row,col = spec_ense_test_scaled.shape\n",
    "spec_ense_test_reshaped = spec_ense_test_scaled.reshape((N,row,col,1))\n",
    "N,row,col = mel_ense_test_scaled.shape\n",
    "mel_ense_test_reshaped = mel_ense_test_scaled.reshape((N,row,col,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 3 models\n",
    "y_ense_prob1 = model_mfcc.predict(mfcc_ense_train_reshaped)\n",
    "y_ense_pred1 = np.argmax(y_ense_prob1, axis= -1)\n",
    "\n",
    "y_ense_prob2 = model_spec.predict(spec_ense_train_reshaped)\n",
    "y_ense_pred2 = np.argmax(y_ense_prob2, axis= -1)\n",
    "\n",
    "y_ense_prob3 = model_mel.predict(mel_ense_train_reshaped)\n",
    "y_ense_pred3 = np.argmax(y_ense_prob3, axis= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2329d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vote for most accuracte prediction\n",
    "def get_majority(pred) :\n",
    "    N = len(pred[0]) # num of examples\n",
    "    vote = [] \n",
    "    for i in range(N) :\n",
    "        elements = [j[i] for j in pred] # 3 Prediction results  using 3 different model\n",
    "        elements = np.array(elements)\n",
    "        uniq, freq = np.unique(elements, return_counts= True) # Count the occurence of unqiue result\n",
    "        vote.append(uniq[np.argmax(freq)])# Choose the prediction with most occurence\n",
    "    \n",
    "    vote = np.array(vote)\n",
    "    return vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 different predictions\n",
    "train_pred = [y_ense_pred1, y_ense_pred2, y_ense_pred3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d17b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = get_majority(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab661e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "train_corr = len(y_train_pred) - np.count_nonzero(y_train_pred - y_ense_train)\n",
    "train_acc = np.round((train_corr/ len(y_train_pred)),4)\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f79be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ensembled models\n",
    "y_test_prob1 = model_spec.predict(spec_ense_test_reshaped)\n",
    "y_test_pred1 = np.argmax(y_test_prob1, axis= -1)\n",
    "\n",
    "y_test_prob2 = model_mfcc.predict(mfcc_ense_test_reshaped)\n",
    "y_test_pred2 = np.argmax(y_test_prob2, axis= -1)\n",
    "\n",
    "y_test_prob3 = model_mel.predict(mel_ense_test_reshaped)\n",
    "y_test_pred3 = np.argmax(y_test_prob3, axis= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434ad020",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = [y_test_pred1, y_test_pred2, y_test_pred3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = get_majority(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "test_corr = len(y_test_pred) - np.count_nonzero(y_test_pred - y_ense_test)\n",
    "test_acc = np.round((test_corr/ len(y_test_pred)),4)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beafc40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_ense = confusion_matrix(y_ense_test,y_test_pred)\n",
    "cm_display_ense = ConfusionMatrixDisplay(confusion_matrix = cm_ense, display_labels = ['Happy', 'Relaxed', 'Sad'])\n",
    "print(classification_report(y_ense_test, y_test_pred, target_names = ['Happy', 'Relaxed', 'Sad']))\n",
    "cm_display_ense.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
