{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ea7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32e9d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''--------- 1. Data Manipulation ---------'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "'''--------- 2. Data Preprocessing ---------'''\n",
    "from sklearn.preprocessing import LabelEncoder #Encode Non-numeric Var\n",
    "from sklearn.preprocessing import MinMaxScaler # Feature Scaling\n",
    "from sklearn.model_selection import train_test_split #Train Test Validation Split\n",
    "'''--------- 3. Data Visualization ---------'''\n",
    "import matplotlib.pyplot as plt\n",
    "'''--------- 4. Model Training ---------'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "'''--------- 5. Model Evluation ---------'''\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07327a4a",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "### Dataset 1\n",
    "**About dataset**\n",
    "- 900 ~30 second audio clips gathered from AllMusic API\n",
    "- Annotated into 4 quadrants based on valance and arousal according to Russell's model\n",
    "- Audios are organized in 4 folders (Q1 to Q4)\n",
    "- Equally stratified dataset with each classes 250 songs\n",
    "\n",
    "**Acknowledgements**<br>\n",
    "Source: http://mir.dei.uc.pt/downloads.html\n",
    "\n",
    "**If you use it, please cite the following article(s):**\n",
    "\n",
    "Panda R., Malheiro R. & Paiva R. P. (2018). \"Novel audio features for music emotion recognition\". IEEE Transactions on Affective Computing (IEEE early access). DOI: 10.1109/TAFFC.2018.2820691.\n",
    "\n",
    "Panda R., Malheiro R., Paiva R. P. (2018). \"Musical Texture and Expressivity Features for Music Emotion Recognition\". 19th International Society for Music Information Retrieval Conference -- ISMIR 2018, Paris, France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b5fd3ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>scale</th>\n",
       "      <th>key</th>\n",
       "      <th>tempo</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>chroma_mean</th>\n",
       "      <th>chroma_var</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_var_16</th>\n",
       "      <th>mfcc_mean_17</th>\n",
       "      <th>mfcc_var_17</th>\n",
       "      <th>mfcc_mean_18</th>\n",
       "      <th>mfcc_var_18</th>\n",
       "      <th>mfcc_mean_19</th>\n",
       "      <th>mfcc_var_19</th>\n",
       "      <th>mfcc_mean_20</th>\n",
       "      <th>mfcc_var_20</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>D:/UM/Project/Mozartify/project/Datasets/audio...</td>\n",
       "      <td>major</td>\n",
       "      <td>D</td>\n",
       "      <td>135.999178</td>\n",
       "      <td>0.171184</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.344088</td>\n",
       "      <td>0.098565</td>\n",
       "      <td>2289.203183</td>\n",
       "      <td>...</td>\n",
       "      <td>97.696182</td>\n",
       "      <td>-3.537810</td>\n",
       "      <td>71.402687</td>\n",
       "      <td>-0.436729</td>\n",
       "      <td>66.260963</td>\n",
       "      <td>-0.202857</td>\n",
       "      <td>59.259083</td>\n",
       "      <td>0.894741</td>\n",
       "      <td>47.133595</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D:/UM/Project/Mozartify/project/Datasets/audio...</td>\n",
       "      <td>major</td>\n",
       "      <td>E</td>\n",
       "      <td>107.666016</td>\n",
       "      <td>0.106427</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.416452</td>\n",
       "      <td>0.090011</td>\n",
       "      <td>2129.307062</td>\n",
       "      <td>...</td>\n",
       "      <td>37.896637</td>\n",
       "      <td>-9.209418</td>\n",
       "      <td>46.455044</td>\n",
       "      <td>-1.426528</td>\n",
       "      <td>50.276150</td>\n",
       "      <td>-3.567492</td>\n",
       "      <td>65.857529</td>\n",
       "      <td>1.226228</td>\n",
       "      <td>85.487991</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>D:/UM/Project/Mozartify/project/Datasets/audio...</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>0.241972</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>0.435837</td>\n",
       "      <td>0.084253</td>\n",
       "      <td>2980.267152</td>\n",
       "      <td>...</td>\n",
       "      <td>67.306412</td>\n",
       "      <td>-6.006174</td>\n",
       "      <td>66.395699</td>\n",
       "      <td>-1.117358</td>\n",
       "      <td>49.001869</td>\n",
       "      <td>-4.630496</td>\n",
       "      <td>50.317497</td>\n",
       "      <td>0.654567</td>\n",
       "      <td>79.517960</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>D:/UM/Project/Mozartify/project/Datasets/audio...</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>107.666016</td>\n",
       "      <td>0.120562</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.420664</td>\n",
       "      <td>0.079768</td>\n",
       "      <td>2882.799693</td>\n",
       "      <td>...</td>\n",
       "      <td>33.676331</td>\n",
       "      <td>-4.147554</td>\n",
       "      <td>37.201412</td>\n",
       "      <td>-3.797808</td>\n",
       "      <td>32.774509</td>\n",
       "      <td>-8.426100</td>\n",
       "      <td>32.341358</td>\n",
       "      <td>-6.023935</td>\n",
       "      <td>30.663700</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>D:/UM/Project/Mozartify/project/Datasets/audio...</td>\n",
       "      <td>major</td>\n",
       "      <td>E</td>\n",
       "      <td>129.199219</td>\n",
       "      <td>0.192818</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.274221</td>\n",
       "      <td>0.085475</td>\n",
       "      <td>2146.962603</td>\n",
       "      <td>...</td>\n",
       "      <td>28.778049</td>\n",
       "      <td>-10.854812</td>\n",
       "      <td>36.313950</td>\n",
       "      <td>-0.480542</td>\n",
       "      <td>47.509182</td>\n",
       "      <td>-4.177841</td>\n",
       "      <td>60.641903</td>\n",
       "      <td>6.327812</td>\n",
       "      <td>64.390320</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>968</td>\n",
       "      <td>D:/UM/Project/Mozartify/project/Datasets/audio...</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>151.999081</td>\n",
       "      <td>0.097105</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.293956</td>\n",
       "      <td>0.088207</td>\n",
       "      <td>1997.276683</td>\n",
       "      <td>...</td>\n",
       "      <td>52.399574</td>\n",
       "      <td>-18.951229</td>\n",
       "      <td>71.105469</td>\n",
       "      <td>-6.146902</td>\n",
       "      <td>61.915462</td>\n",
       "      <td>-16.994026</td>\n",
       "      <td>55.398777</td>\n",
       "      <td>-14.183487</td>\n",
       "      <td>64.577774</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>969</td>\n",
       "      <td>D:/UM/Project/Mozartify/project/Datasets/audio...</td>\n",
       "      <td>minor</td>\n",
       "      <td>G#</td>\n",
       "      <td>89.102909</td>\n",
       "      <td>0.083837</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.272151</td>\n",
       "      <td>0.084929</td>\n",
       "      <td>1331.011559</td>\n",
       "      <td>...</td>\n",
       "      <td>37.900272</td>\n",
       "      <td>-11.959914</td>\n",
       "      <td>43.625828</td>\n",
       "      <td>-5.335443</td>\n",
       "      <td>40.348934</td>\n",
       "      <td>-10.943409</td>\n",
       "      <td>37.393105</td>\n",
       "      <td>-15.349643</td>\n",
       "      <td>56.387405</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>970</td>\n",
       "      <td>D:/UM/Project/Mozartify/project/Datasets/audio...</td>\n",
       "      <td>major</td>\n",
       "      <td>E</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>0.076661</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.237400</td>\n",
       "      <td>0.089330</td>\n",
       "      <td>1681.161502</td>\n",
       "      <td>...</td>\n",
       "      <td>46.293671</td>\n",
       "      <td>-5.706831</td>\n",
       "      <td>39.779736</td>\n",
       "      <td>-3.286500</td>\n",
       "      <td>47.729607</td>\n",
       "      <td>1.990399</td>\n",
       "      <td>70.187508</td>\n",
       "      <td>5.452133</td>\n",
       "      <td>70.151512</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>971</td>\n",
       "      <td>D:/UM/Project/Mozartify/project/Datasets/audio...</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>0.071242</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.263051</td>\n",
       "      <td>0.092084</td>\n",
       "      <td>2075.571372</td>\n",
       "      <td>...</td>\n",
       "      <td>45.630798</td>\n",
       "      <td>-16.532892</td>\n",
       "      <td>45.669132</td>\n",
       "      <td>-11.235711</td>\n",
       "      <td>48.995541</td>\n",
       "      <td>-15.730806</td>\n",
       "      <td>54.862488</td>\n",
       "      <td>-15.158969</td>\n",
       "      <td>68.118660</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>972</td>\n",
       "      <td>D:/UM/Project/Mozartify/project/Datasets/audio...</td>\n",
       "      <td>minor</td>\n",
       "      <td>F#</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>0.054451</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.226404</td>\n",
       "      <td>0.087524</td>\n",
       "      <td>1857.736709</td>\n",
       "      <td>...</td>\n",
       "      <td>46.131042</td>\n",
       "      <td>-5.977736</td>\n",
       "      <td>78.518745</td>\n",
       "      <td>2.433602</td>\n",
       "      <td>74.181198</td>\n",
       "      <td>-2.228051</td>\n",
       "      <td>73.092354</td>\n",
       "      <td>-5.549421</td>\n",
       "      <td>73.862915</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>973 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               file  scale key  \\\n",
       "0             0  D:/UM/Project/Mozartify/project/Datasets/audio...  major   D   \n",
       "1             1  D:/UM/Project/Mozartify/project/Datasets/audio...  major   E   \n",
       "2             2  D:/UM/Project/Mozartify/project/Datasets/audio...  major   A   \n",
       "3             3  D:/UM/Project/Mozartify/project/Datasets/audio...  major   A   \n",
       "4             4  D:/UM/Project/Mozartify/project/Datasets/audio...  major   E   \n",
       "..          ...                                                ...    ...  ..   \n",
       "968         968  D:/UM/Project/Mozartify/project/Datasets/audio...  major   A   \n",
       "969         969  D:/UM/Project/Mozartify/project/Datasets/audio...  minor  G#   \n",
       "970         970  D:/UM/Project/Mozartify/project/Datasets/audio...  major   E   \n",
       "971         971  D:/UM/Project/Mozartify/project/Datasets/audio...  major   A   \n",
       "972         972  D:/UM/Project/Mozartify/project/Datasets/audio...  minor  F#   \n",
       "\n",
       "          tempo  rms_mean   rms_var  chroma_mean  chroma_var  centroid_mean  \\\n",
       "0    135.999178  0.171184  0.003348     0.344088    0.098565    2289.203183   \n",
       "1    107.666016  0.106427  0.000725     0.416452    0.090011    2129.307062   \n",
       "2     99.384014  0.241972  0.010910     0.435837    0.084253    2980.267152   \n",
       "3    107.666016  0.120562  0.002160     0.420664    0.079768    2882.799693   \n",
       "4    129.199219  0.192818  0.003956     0.274221    0.085475    2146.962603   \n",
       "..          ...       ...       ...          ...         ...            ...   \n",
       "968  151.999081  0.097105  0.000582     0.293956    0.088207    1997.276683   \n",
       "969   89.102909  0.083837  0.001618     0.272151    0.084929    1331.011559   \n",
       "970   99.384014  0.076661  0.000290     0.237400    0.089330    1681.161502   \n",
       "971   99.384014  0.071242  0.001089     0.263051    0.092084    2075.571372   \n",
       "972   99.384014  0.054451  0.000717     0.226404    0.087524    1857.736709   \n",
       "\n",
       "     ...  mfcc_var_16  mfcc_mean_17  mfcc_var_17  mfcc_mean_18  mfcc_var_18  \\\n",
       "0    ...    97.696182     -3.537810    71.402687     -0.436729    66.260963   \n",
       "1    ...    37.896637     -9.209418    46.455044     -1.426528    50.276150   \n",
       "2    ...    67.306412     -6.006174    66.395699     -1.117358    49.001869   \n",
       "3    ...    33.676331     -4.147554    37.201412     -3.797808    32.774509   \n",
       "4    ...    28.778049    -10.854812    36.313950     -0.480542    47.509182   \n",
       "..   ...          ...           ...          ...           ...          ...   \n",
       "968  ...    52.399574    -18.951229    71.105469     -6.146902    61.915462   \n",
       "969  ...    37.900272    -11.959914    43.625828     -5.335443    40.348934   \n",
       "970  ...    46.293671     -5.706831    39.779736     -3.286500    47.729607   \n",
       "971  ...    45.630798    -16.532892    45.669132    -11.235711    48.995541   \n",
       "972  ...    46.131042     -5.977736    78.518745      2.433602    74.181198   \n",
       "\n",
       "     mfcc_mean_19  mfcc_var_19  mfcc_mean_20  mfcc_var_20   mood  \n",
       "0       -0.202857    59.259083      0.894741    47.133595  happy  \n",
       "1       -3.567492    65.857529      1.226228    85.487991  happy  \n",
       "2       -4.630496    50.317497      0.654567    79.517960  happy  \n",
       "3       -8.426100    32.341358     -6.023935    30.663700  happy  \n",
       "4       -4.177841    60.641903      6.327812    64.390320  happy  \n",
       "..            ...          ...           ...          ...    ...  \n",
       "968    -16.994026    55.398777    -14.183487    64.577774    sad  \n",
       "969    -10.943409    37.393105    -15.349643    56.387405    sad  \n",
       "970      1.990399    70.187508      5.452133    70.151512    sad  \n",
       "971    -15.730806    54.862488    -15.158969    68.118660    sad  \n",
       "972     -2.228051    73.092354     -5.549421    73.862915    sad  \n",
       "\n",
       "[973 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset1\n",
    "df1 = pd.read_excel(\"D:/UM/Project/Mozartify/project/Datasets/Features/Features1D/Features1D.xlsx\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c88b98b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 973 entries, 0 to 972\n",
      "Data columns (total 60 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     973 non-null    int64  \n",
      " 1   file           973 non-null    object \n",
      " 2   scale          973 non-null    object \n",
      " 3   key            973 non-null    object \n",
      " 4   tempo          973 non-null    float64\n",
      " 5   rms_mean       973 non-null    float64\n",
      " 6   rms_var        973 non-null    float64\n",
      " 7   chroma_mean    973 non-null    float64\n",
      " 8   chroma_var     973 non-null    float64\n",
      " 9   centroid_mean  973 non-null    float64\n",
      " 10  centroid_var   973 non-null    float64\n",
      " 11  rolloff_mean   973 non-null    float64\n",
      " 12  roll_off_var   973 non-null    float64\n",
      " 13  zcr_mean       973 non-null    float64\n",
      " 14  zcr_var        973 non-null    float64\n",
      " 15  tonnetz_mean   973 non-null    float64\n",
      " 16  tonnetz_var    973 non-null    float64\n",
      " 17  mel_mean       973 non-null    float64\n",
      " 18  mel_var        973 non-null    float64\n",
      " 19  mfcc_mean_1    973 non-null    float64\n",
      " 20  mfcc_var_1     973 non-null    float64\n",
      " 21  mfcc_mean_2    973 non-null    float64\n",
      " 22  mfcc_var_2     973 non-null    float64\n",
      " 23  mfcc_mean_3    973 non-null    float64\n",
      " 24  mfcc_var_3     973 non-null    float64\n",
      " 25  mfcc_mean_4    973 non-null    float64\n",
      " 26  mfcc_var_4     973 non-null    float64\n",
      " 27  mfcc_mean_5    973 non-null    float64\n",
      " 28  mfcc_var_5     973 non-null    float64\n",
      " 29  mfcc_mean_6    973 non-null    float64\n",
      " 30  mfcc_var_6     973 non-null    float64\n",
      " 31  mfcc_mean_7    973 non-null    float64\n",
      " 32  mfcc_var_7     973 non-null    float64\n",
      " 33  mfcc_mean_8    973 non-null    float64\n",
      " 34  mfcc_var_8     973 non-null    float64\n",
      " 35  mfcc_mean_9    973 non-null    float64\n",
      " 36  mfcc_var_9     973 non-null    float64\n",
      " 37  mfcc_mean_10   973 non-null    float64\n",
      " 38  mfcc_var_10    973 non-null    float64\n",
      " 39  mfcc_mean_11   973 non-null    float64\n",
      " 40  mfcc_var_11    973 non-null    float64\n",
      " 41  mfcc_mean_12   973 non-null    float64\n",
      " 42  mfcc_var_12    973 non-null    float64\n",
      " 43  mfcc_mean_13   973 non-null    float64\n",
      " 44  mfcc_var_13    973 non-null    float64\n",
      " 45  mfcc_mean_14   973 non-null    float64\n",
      " 46  mfcc_var_14    973 non-null    float64\n",
      " 47  mfcc_mean_15   973 non-null    float64\n",
      " 48  mfcc_var_15    973 non-null    float64\n",
      " 49  mfcc_mean_16   973 non-null    float64\n",
      " 50  mfcc_var_16    973 non-null    float64\n",
      " 51  mfcc_mean_17   973 non-null    float64\n",
      " 52  mfcc_var_17    973 non-null    float64\n",
      " 53  mfcc_mean_18   973 non-null    float64\n",
      " 54  mfcc_var_18    973 non-null    float64\n",
      " 55  mfcc_mean_19   973 non-null    float64\n",
      " 56  mfcc_var_19    973 non-null    float64\n",
      " 57  mfcc_mean_20   973 non-null    float64\n",
      " 58  mfcc_var_20    973 non-null    float64\n",
      " 59  mood           973 non-null    object \n",
      "dtypes: float64(55), int64(1), object(4)\n",
      "memory usage: 456.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a41ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tempo</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>chroma_mean</th>\n",
       "      <th>chroma_var</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>centroid_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>roll_off_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_mean_16</th>\n",
       "      <th>mfcc_var_16</th>\n",
       "      <th>mfcc_mean_17</th>\n",
       "      <th>mfcc_var_17</th>\n",
       "      <th>mfcc_mean_18</th>\n",
       "      <th>mfcc_var_18</th>\n",
       "      <th>mfcc_mean_19</th>\n",
       "      <th>mfcc_var_19</th>\n",
       "      <th>mfcc_mean_20</th>\n",
       "      <th>mfcc_var_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>9.730000e+02</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>9.730000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>486.000000</td>\n",
       "      <td>122.326785</td>\n",
       "      <td>0.118356</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.329636</td>\n",
       "      <td>0.088357</td>\n",
       "      <td>1871.439674</td>\n",
       "      <td>3.862950e+05</td>\n",
       "      <td>3796.562374</td>\n",
       "      <td>1.799023e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.049367</td>\n",
       "      <td>70.397937</td>\n",
       "      <td>-3.300858</td>\n",
       "      <td>70.950847</td>\n",
       "      <td>-1.941788</td>\n",
       "      <td>72.751296</td>\n",
       "      <td>-2.665623</td>\n",
       "      <td>76.034758</td>\n",
       "      <td>-1.853424</td>\n",
       "      <td>82.237559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>281.025206</td>\n",
       "      <td>21.454196</td>\n",
       "      <td>0.056419</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.068965</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>658.123865</td>\n",
       "      <td>3.301376e+05</td>\n",
       "      <td>1528.810501</td>\n",
       "      <td>1.418762e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.246275</td>\n",
       "      <td>37.247865</td>\n",
       "      <td>5.542685</td>\n",
       "      <td>38.941899</td>\n",
       "      <td>5.093315</td>\n",
       "      <td>40.392693</td>\n",
       "      <td>5.224362</td>\n",
       "      <td>40.732825</td>\n",
       "      <td>4.916512</td>\n",
       "      <td>48.856245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.999794</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.131688</td>\n",
       "      <td>0.065206</td>\n",
       "      <td>375.472632</td>\n",
       "      <td>4.007574e+03</td>\n",
       "      <td>523.105966</td>\n",
       "      <td>1.089884e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.835148</td>\n",
       "      <td>20.954960</td>\n",
       "      <td>-24.893364</td>\n",
       "      <td>21.495405</td>\n",
       "      <td>-20.297907</td>\n",
       "      <td>21.370155</td>\n",
       "      <td>-19.804493</td>\n",
       "      <td>19.875721</td>\n",
       "      <td>-18.626137</td>\n",
       "      <td>17.969856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>107.666016</td>\n",
       "      <td>0.076826</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.280484</td>\n",
       "      <td>0.084610</td>\n",
       "      <td>1382.944669</td>\n",
       "      <td>1.468872e+05</td>\n",
       "      <td>2646.252364</td>\n",
       "      <td>7.196876e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.275205</td>\n",
       "      <td>47.986336</td>\n",
       "      <td>-6.707193</td>\n",
       "      <td>46.685753</td>\n",
       "      <td>-5.123790</td>\n",
       "      <td>48.109035</td>\n",
       "      <td>-5.579427</td>\n",
       "      <td>49.918827</td>\n",
       "      <td>-4.784280</td>\n",
       "      <td>52.087006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>486.000000</td>\n",
       "      <td>123.046875</td>\n",
       "      <td>0.108863</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.325388</td>\n",
       "      <td>0.088237</td>\n",
       "      <td>1817.264611</td>\n",
       "      <td>2.860354e+05</td>\n",
       "      <td>3743.848123</td>\n",
       "      <td>1.431462e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.367494</td>\n",
       "      <td>61.631184</td>\n",
       "      <td>-4.083600</td>\n",
       "      <td>61.393219</td>\n",
       "      <td>-1.516343</td>\n",
       "      <td>61.805428</td>\n",
       "      <td>-3.003905</td>\n",
       "      <td>64.925056</td>\n",
       "      <td>-1.690674</td>\n",
       "      <td>68.933380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>729.000000</td>\n",
       "      <td>135.999178</td>\n",
       "      <td>0.150578</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.376347</td>\n",
       "      <td>0.092118</td>\n",
       "      <td>2331.611628</td>\n",
       "      <td>5.280622e+05</td>\n",
       "      <td>4902.536263</td>\n",
       "      <td>2.479123e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586643</td>\n",
       "      <td>83.831070</td>\n",
       "      <td>-0.359441</td>\n",
       "      <td>82.718422</td>\n",
       "      <td>1.710763</td>\n",
       "      <td>85.849907</td>\n",
       "      <td>-0.064738</td>\n",
       "      <td>89.789009</td>\n",
       "      <td>1.351306</td>\n",
       "      <td>97.345245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>972.000000</td>\n",
       "      <td>198.768029</td>\n",
       "      <td>0.316388</td>\n",
       "      <td>0.023626</td>\n",
       "      <td>0.578017</td>\n",
       "      <td>0.111998</td>\n",
       "      <td>3703.270406</td>\n",
       "      <td>2.775176e+06</td>\n",
       "      <td>7815.759200</td>\n",
       "      <td>8.834975e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>16.275961</td>\n",
       "      <td>435.665466</td>\n",
       "      <td>15.933263</td>\n",
       "      <td>514.815186</td>\n",
       "      <td>13.124250</td>\n",
       "      <td>444.994965</td>\n",
       "      <td>16.365273</td>\n",
       "      <td>392.186249</td>\n",
       "      <td>15.270178</td>\n",
       "      <td>442.129852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       tempo    rms_mean     rms_var  chroma_mean  \\\n",
       "count  973.000000  973.000000  973.000000  973.000000   973.000000   \n",
       "mean   486.000000  122.326785    0.118356    0.002878     0.329636   \n",
       "std    281.025206   21.454196    0.056419    0.002753     0.068965   \n",
       "min      0.000000   33.999794    0.006621    0.000022     0.131688   \n",
       "25%    243.000000  107.666016    0.076826    0.001124     0.280484   \n",
       "50%    486.000000  123.046875    0.108863    0.002086     0.325388   \n",
       "75%    729.000000  135.999178    0.150578    0.003653     0.376347   \n",
       "max    972.000000  198.768029    0.316388    0.023626     0.578017   \n",
       "\n",
       "       chroma_var  centroid_mean  centroid_var  rolloff_mean  roll_off_var  \\\n",
       "count  973.000000     973.000000  9.730000e+02    973.000000  9.730000e+02   \n",
       "mean     0.088357    1871.439674  3.862950e+05   3796.562374  1.799023e+06   \n",
       "std      0.006010     658.123865  3.301376e+05   1528.810501  1.418762e+06   \n",
       "min      0.065206     375.472632  4.007574e+03    523.105966  1.089884e+04   \n",
       "25%      0.084610    1382.944669  1.468872e+05   2646.252364  7.196876e+05   \n",
       "50%      0.088237    1817.264611  2.860354e+05   3743.848123  1.431462e+06   \n",
       "75%      0.092118    2331.611628  5.280622e+05   4902.536263  2.479123e+06   \n",
       "max      0.111998    3703.270406  2.775176e+06   7815.759200  8.834975e+06   \n",
       "\n",
       "       ...  mfcc_mean_16  mfcc_var_16  mfcc_mean_17  mfcc_var_17  \\\n",
       "count  ...    973.000000   973.000000    973.000000   973.000000   \n",
       "mean   ...     -2.049367    70.397937     -3.300858    70.950847   \n",
       "std    ...      5.246275    37.247865      5.542685    38.941899   \n",
       "min    ...    -23.835148    20.954960    -24.893364    21.495405   \n",
       "25%    ...     -5.275205    47.986336     -6.707193    46.685753   \n",
       "50%    ...     -1.367494    61.631184     -4.083600    61.393219   \n",
       "75%    ...      1.586643    83.831070     -0.359441    82.718422   \n",
       "max    ...     16.275961   435.665466     15.933263   514.815186   \n",
       "\n",
       "       mfcc_mean_18  mfcc_var_18  mfcc_mean_19  mfcc_var_19  mfcc_mean_20  \\\n",
       "count    973.000000   973.000000    973.000000   973.000000    973.000000   \n",
       "mean      -1.941788    72.751296     -2.665623    76.034758     -1.853424   \n",
       "std        5.093315    40.392693      5.224362    40.732825      4.916512   \n",
       "min      -20.297907    21.370155    -19.804493    19.875721    -18.626137   \n",
       "25%       -5.123790    48.109035     -5.579427    49.918827     -4.784280   \n",
       "50%       -1.516343    61.805428     -3.003905    64.925056     -1.690674   \n",
       "75%        1.710763    85.849907     -0.064738    89.789009      1.351306   \n",
       "max       13.124250   444.994965     16.365273   392.186249     15.270178   \n",
       "\n",
       "       mfcc_var_20  \n",
       "count   973.000000  \n",
       "mean     82.237559  \n",
       "std      48.856245  \n",
       "min      17.969856  \n",
       "25%      52.087006  \n",
       "50%      68.933380  \n",
       "75%      97.345245  \n",
       "max     442.129852  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fce297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0       tempo  rms_mean   rms_var  chroma_mean  chroma_var  \\\n",
      "mood                                                                         \n",
      "happy       161.0  122.184162  0.144312  0.003395     0.378268    0.085952   \n",
      "relax       485.0  122.180199  0.104465  0.002653     0.307227    0.089406   \n",
      "sad         810.0  122.615117  0.106450  0.002588     0.303711    0.089698   \n",
      "\n",
      "       centroid_mean   centroid_var  rolloff_mean  roll_off_var  ...  \\\n",
      "mood                                                             ...   \n",
      "happy    2365.546454  373575.994834   4914.590015  1.507072e+06  ...   \n",
      "relax    1561.184667  442691.978249   3120.298016  2.249632e+06  ...   \n",
      "sad      1690.628556  342538.667756   3361.679261  1.638569e+06  ...   \n",
      "\n",
      "       mfcc_mean_16  mfcc_var_16  mfcc_mean_17  mfcc_var_17  mfcc_mean_18  \\\n",
      "mood                                                                        \n",
      "happy     -1.373352    57.319127     -2.999226    58.095549     -1.147069   \n",
      "relax     -1.978331    80.309944     -2.897631    81.360577     -2.004618   \n",
      "sad       -2.792259    73.484255     -4.003863    73.317306     -2.668786   \n",
      "\n",
      "       mfcc_var_18  mfcc_mean_19  mfcc_var_19  mfcc_mean_20  mfcc_var_20  \n",
      "mood                                                                      \n",
      "happy    59.728584     -2.248551    65.377819     -1.209178    67.984067  \n",
      "relax    84.298523     -2.534304    84.423146     -2.110647    91.233271  \n",
      "sad      74.146643     -3.211449    78.237729     -2.236482    87.407626  \n",
      "\n",
      "[3 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = df1.select_dtypes(include=[np.number])\n",
    "\n",
    "# Group by 'mood' and calculate mean for numeric columns only\n",
    "grouped_mean = df1.groupby('mood')[numeric_columns.columns].mean()\n",
    "print(grouped_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e803fa86",
   "metadata": {},
   "source": [
    "### Dataset 2\n",
    "**About dataset**\n",
    "- 400 ~30 second audio clips gathered from erbal and non-verbal music from different genres of Turkish music\n",
    "- Annotated into 4 quadrants based on valance and arousal according to Russell's model.\n",
    "- Audios are organized in 4 categories - Happy, Sad, Angry, Relax\n",
    "- Equally stratified dataset with each classes 100 songs\n",
    "\n",
    "**Acknowledgements**<br>\n",
    "source:https://www.kaggle.com/datasets/blaler/turkish-music-emotion-dataset\n",
    "\n",
    "**If you use it, please cite the following article(s):**<br>\n",
    "Bilal Er, M., & Aydilek, I. B. (2019). Music emotion recognition by using chroma spectrogram and deep visual features. Journal of Computational Intelligent Systems, 12(2), 1622–1634. International Journal of Computational Intelligence Systems, DOI: [Web Link] https://doi.org/10.2991/ijcis.d.191216.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eca9703",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing\n",
    "### 2.1 Define Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be28fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy', 'relax', 'sad'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = df1.drop(['mood'],axis=1)\n",
    "y1 = df1['mood']\n",
    "np.unique(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d5d1f",
   "metadata": {},
   "source": [
    "### 2.2 Encode the non-numerical features labels\n",
    "\n",
    "**Encode the labels in numerical way:**\n",
    "- Happy: 1 \n",
    "- Angry: 0 \n",
    "- Relaxed: 2 \n",
    "- Sad: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e1d89f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y1)\n",
    "y1 = le.transform(y1)\n",
    "np.unique(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a79f5",
   "metadata": {},
   "source": [
    "**Then encode the non-numeric variable scale:**\n",
    "- major: 0\n",
    "- minor: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e64ba99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['major', 'minor'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1['scale'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53bcb6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(X1['scale'])\n",
    "X1['scale'] = le.transform(X1['scale'])\n",
    "X1['scale'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6282266b",
   "metadata": {},
   "source": [
    "**Finally, encode the non-numeric variable key:**\n",
    "- A: 0\n",
    "- A#: 1\n",
    "- B: 2\n",
    "- C: 3\n",
    "- C#: 4\n",
    "- D: 5\n",
    "- D#: 6\n",
    "- E: 7\n",
    "- F: 8\n",
    "- F#: 9\n",
    "- G: 10\n",
    "- G#: 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbc4c682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D', 'E', 'A', 'F', 'C', 'G#', 'G', 'B', 'F#', 'C#', 'A#', 'D#'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1['key'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7324da64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  7,  0,  8,  3, 11, 10,  2,  9,  4,  1,  6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(X1['key'])\n",
    "X1['key'] = le.transform(X1['key'])\n",
    "X1['key'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c55b16",
   "metadata": {},
   "source": [
    "### 2.3 Train Test Validation Split\n",
    "Finally, split the dataset into train and test set, 80% of data are used as train set, 10% of data are used as test set and the remaining ones are used for validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cfd54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, \n",
    "                                                        train_size = 0.8, \n",
    "                                                        random_state = 13,  \n",
    "                                                        stratify = y1)\n",
    "\n",
    "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, \n",
    "                                                      train_size = 0.8, \n",
    "                                                      random_state = 13,  \n",
    "                                                      stratify = y1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a1c809",
   "metadata": {},
   "source": [
    "### 2.4 Feature Scaling\n",
    "As the range of the variales varies distinctly, in order to make the learning process better, the features need to be scaled into similar ranges. Here the Min-Max Scaler is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38e763e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X1_train_scaled = scaler.fit_transform(X1_train.drop('file',axis=1))\n",
    "X1_val_scaled = scaler.fit_transform(X1_val.drop('file',axis=1))\n",
    "X1_test_scaled = scaler.fit_transform(X1_test.drop('file',axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f2ff7",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963df061",
   "metadata": {},
   "source": [
    "### 3.1 Overfitting problems and comparison study for improving the validation accuracy\n",
    "Using data in dataset 1 as training data, the model always suffers from the overfitting problems regardless of the\n",
    "adjustment of the parameters and number of input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5153ff50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define Model Builder of 3 conv1D layers and 2 fully connected layers\n",
    "# Input data and paras of layers are changable\n",
    "\n",
    "def modelBuilder3L(X_train,\n",
    "                  f1,k1,a1,\n",
    "                  f2,k2,a2,\n",
    "                  f3,k3,a3,\n",
    "                  d1,dr1,da1,r1,\n",
    "                  d2,dr2,da2,r2,\n",
    "                  num):\n",
    "    '''\n",
    "    args:\n",
    "    \n",
    "    X_train: training data\n",
    "    f1,k1,a1: num of filters, filter size and activation func of 1st conv1D layer\n",
    "    f2,k2,a2: num of filters, filter size and activation func of 2nd conv1D layer\n",
    "    f3,k3,a3: num of filters, filter size and activation func of 3rd conv1D layer\n",
    "    d1,dr1,da1, r1: num of units, dropout, activation func and regularizer para of 1st fully connected layer\n",
    "    d2,dr2,da2, r2: num of units, dropout, activation func and regularizer para of 2nd fully connected layer\n",
    "    num: integer for distinguishing different model\n",
    "    \n",
    "    return:\n",
    "    model\n",
    "    \n",
    "    '''\n",
    "    model = Sequential(name=\"Conv1D_\"+str(num))\n",
    "    m,n = X_train.shape\n",
    "    #layer 1\n",
    "    model.add(Conv1D(filters = f1, kernel_size = k1, input_shape = (n,1), padding = 'same', activation = a1, name ='Conv1D_1'))\n",
    "    model.add(BatchNormalization(name = \"BN1\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling1\"))\n",
    "    #layer 2\n",
    "    model.add(Conv1D(filters = f2, kernel_size = k2, activation = a2, padding='same', name = \"Conv1D_2\"))\n",
    "    model.add(BatchNormalization(name = \"BN2\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling2\"))\n",
    "    #layer 3\n",
    "    model.add(Conv1D(filters = f3, kernel_size = k3, activation = a3, padding='same', name = \"Conv1D_3\"))\n",
    "    model.add(BatchNormalization(name = \"BN3\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling3\"))\n",
    "    #Flatten output\n",
    "    model.add(Flatten(name = \"Flatten\"))\n",
    "    #Fully connected layer 4\n",
    "    model.add(Dense(d1, activation = da1, name = \"Dense_1\"))\n",
    "    #Prevent overfitting\n",
    "    model.add(Dropout(dr1, name = \"Dropout_1\"))\n",
    "    #Fully connected layer 6\n",
    "    model.add(Dense(d2, activation = da2, name = \"Dense_2\"))\n",
    "    #Prevent overfitting\n",
    "    model.add(Dropout(dr2, name = \"Dropout_2\"))\n",
    "    #Output layer\n",
    "    model.add(Dense(4, activation = 'softmax', name = \"Softmax\"))\n",
    "    #model compiling\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aca4bb89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Conv1D_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Conv1D_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m96\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m7,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m28,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,548</span> (189.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m48,548\u001b[0m (189.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,388</span> (189.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,388\u001b[0m (189.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0\n",
    "num = 1\n",
    "\n",
    "model1 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "357e957b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.2496 - loss: 1.7874 - val_accuracy: 0.0000e+00 - val_loss: 1.4129\n",
      "Epoch 2/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4992 - loss: 1.1019 - val_accuracy: 0.0000e+00 - val_loss: 1.4560\n",
      "Epoch 3/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5645 - loss: 0.9873 - val_accuracy: 0.0000e+00 - val_loss: 1.4878\n",
      "Epoch 4/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6687 - loss: 0.7986 - val_accuracy: 0.1667 - val_loss: 1.5023\n",
      "Epoch 5/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6428 - loss: 0.7944 - val_accuracy: 0.3782 - val_loss: 1.4981\n",
      "Epoch 6/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7104 - loss: 0.6732 - val_accuracy: 0.3974 - val_loss: 1.4670\n",
      "Epoch 7/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6815 - loss: 0.6794 - val_accuracy: 0.3910 - val_loss: 1.4131\n",
      "Epoch 8/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.6280 - val_accuracy: 0.4103 - val_loss: 1.3438\n",
      "Epoch 9/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7532 - loss: 0.6045 - val_accuracy: 0.4231 - val_loss: 1.2728\n",
      "Epoch 10/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7897 - loss: 0.5158 - val_accuracy: 0.5000 - val_loss: 1.1763\n",
      "Epoch 11/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8169 - loss: 0.4780 - val_accuracy: 0.5577 - val_loss: 1.0782\n",
      "Epoch 12/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8535 - loss: 0.4204 - val_accuracy: 0.6026 - val_loss: 0.9741\n",
      "Epoch 13/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8176 - loss: 0.4265 - val_accuracy: 0.6282 - val_loss: 0.8916\n",
      "Epoch 14/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8480 - loss: 0.4068 - val_accuracy: 0.6603 - val_loss: 0.8241\n",
      "Epoch 15/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8517 - loss: 0.4025 - val_accuracy: 0.6731 - val_loss: 0.7685\n",
      "Epoch 16/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8569 - loss: 0.3378 - val_accuracy: 0.6923 - val_loss: 0.7242\n",
      "Epoch 17/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8802 - loss: 0.3094 - val_accuracy: 0.7051 - val_loss: 0.6897\n",
      "Epoch 18/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.2773 - val_accuracy: 0.7051 - val_loss: 0.6765\n",
      "Epoch 19/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8874 - loss: 0.2767 - val_accuracy: 0.7372 - val_loss: 0.6323\n",
      "Epoch 20/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8858 - loss: 0.2687 - val_accuracy: 0.7500 - val_loss: 0.6166\n",
      "Epoch 21/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.2132 - val_accuracy: 0.7564 - val_loss: 0.5958\n",
      "Epoch 22/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9070 - loss: 0.2467 - val_accuracy: 0.7436 - val_loss: 0.5974\n",
      "Epoch 23/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9131 - loss: 0.1921 - val_accuracy: 0.7628 - val_loss: 0.5847\n",
      "Epoch 24/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9501 - loss: 0.1674 - val_accuracy: 0.7500 - val_loss: 0.5761\n",
      "Epoch 25/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9388 - loss: 0.1932 - val_accuracy: 0.7436 - val_loss: 0.5861\n",
      "Epoch 26/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.1609 - val_accuracy: 0.7628 - val_loss: 0.5743\n",
      "Epoch 27/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9510 - loss: 0.1439 - val_accuracy: 0.7564 - val_loss: 0.5683\n",
      "Epoch 28/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9428 - loss: 0.1438 - val_accuracy: 0.7628 - val_loss: 0.5639\n",
      "Epoch 29/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9614 - loss: 0.1332 - val_accuracy: 0.7821 - val_loss: 0.5430\n",
      "Epoch 30/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9509 - loss: 0.1279 - val_accuracy: 0.7628 - val_loss: 0.5516\n",
      "Epoch 31/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9711 - loss: 0.1199 - val_accuracy: 0.7628 - val_loss: 0.5558\n",
      "Epoch 32/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9753 - loss: 0.0948 - val_accuracy: 0.7628 - val_loss: 0.5271\n",
      "Epoch 33/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9538 - loss: 0.1007 - val_accuracy: 0.7500 - val_loss: 0.5564\n",
      "Epoch 34/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9771 - loss: 0.0939 - val_accuracy: 0.7628 - val_loss: 0.5135\n",
      "Epoch 35/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0679 - val_accuracy: 0.7821 - val_loss: 0.5219\n",
      "Epoch 36/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.0871 - val_accuracy: 0.7756 - val_loss: 0.5337\n",
      "Epoch 37/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.0638 - val_accuracy: 0.7821 - val_loss: 0.5228\n",
      "Epoch 38/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.0616 - val_accuracy: 0.8077 - val_loss: 0.4949\n",
      "Epoch 39/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0544 - val_accuracy: 0.7949 - val_loss: 0.5180\n",
      "Epoch 40/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0438 - val_accuracy: 0.8077 - val_loss: 0.4731\n",
      "Epoch 41/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0470 - val_accuracy: 0.8077 - val_loss: 0.4659\n",
      "Epoch 42/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9719 - loss: 0.0548 - val_accuracy: 0.8013 - val_loss: 0.5082\n",
      "Epoch 43/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0544 - val_accuracy: 0.8013 - val_loss: 0.4742\n",
      "Epoch 44/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0352 - val_accuracy: 0.7821 - val_loss: 0.5317\n",
      "Epoch 45/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0446 - val_accuracy: 0.8013 - val_loss: 0.5277\n",
      "Epoch 46/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0751 - val_accuracy: 0.8397 - val_loss: 0.4590\n",
      "Epoch 47/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0363 - val_accuracy: 0.7885 - val_loss: 0.5123\n",
      "Epoch 48/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0373 - val_accuracy: 0.8013 - val_loss: 0.5354\n",
      "Epoch 49/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0324 - val_accuracy: 0.8013 - val_loss: 0.5037\n",
      "Epoch 50/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0292 - val_accuracy: 0.7821 - val_loss: 0.4875\n",
      "Epoch 51/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0399 - val_accuracy: 0.7885 - val_loss: 0.5264\n",
      "Epoch 52/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0362 - val_accuracy: 0.8013 - val_loss: 0.4756\n",
      "Epoch 53/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0349 - val_accuracy: 0.7949 - val_loss: 0.5320\n",
      "Epoch 54/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0282 - val_accuracy: 0.7821 - val_loss: 0.5807\n",
      "Epoch 55/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0263 - val_accuracy: 0.8269 - val_loss: 0.5273\n",
      "Epoch 56/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0261 - val_accuracy: 0.8205 - val_loss: 0.5714\n",
      "Epoch 57/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0175 - val_accuracy: 0.8077 - val_loss: 0.5332\n",
      "Epoch 58/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0225 - val_accuracy: 0.8077 - val_loss: 0.5232\n",
      "Epoch 59/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0267 - val_accuracy: 0.8141 - val_loss: 0.4850\n",
      "Epoch 60/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0273 - val_accuracy: 0.8013 - val_loss: 0.5401\n",
      "Epoch 61/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0237 - val_accuracy: 0.8077 - val_loss: 0.5328\n",
      "Epoch 62/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0243 - val_accuracy: 0.8077 - val_loss: 0.5255\n",
      "Epoch 63/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0152 - val_accuracy: 0.7949 - val_loss: 0.5835\n",
      "Epoch 64/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0138 - val_accuracy: 0.8013 - val_loss: 0.5742\n",
      "Epoch 65/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0174 - val_accuracy: 0.8077 - val_loss: 0.5682\n",
      "Epoch 66/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0168 - val_accuracy: 0.8205 - val_loss: 0.4970\n",
      "Epoch 67/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0096 - val_accuracy: 0.8205 - val_loss: 0.4951\n",
      "Epoch 68/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0139 - val_accuracy: 0.8205 - val_loss: 0.5044\n",
      "Epoch 69/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0239 - val_accuracy: 0.8397 - val_loss: 0.4673\n",
      "Epoch 70/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.8397 - val_loss: 0.4752\n",
      "Epoch 71/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0137 - val_accuracy: 0.8141 - val_loss: 0.5159\n",
      "Epoch 72/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.8269 - val_loss: 0.5079\n",
      "Epoch 73/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0108 - val_accuracy: 0.8269 - val_loss: 0.5042\n",
      "Epoch 74/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0100 - val_accuracy: 0.8141 - val_loss: 0.5878\n",
      "Epoch 75/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0106 - val_accuracy: 0.7949 - val_loss: 0.5476\n",
      "Epoch 76/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.8077 - val_loss: 0.5614\n",
      "Epoch 77/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.8013 - val_loss: 0.5907\n",
      "Epoch 78/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0069 - val_accuracy: 0.8141 - val_loss: 0.5702\n",
      "Epoch 79/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0060 - val_accuracy: 0.8013 - val_loss: 0.5511\n",
      "Epoch 80/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0082 - val_accuracy: 0.8013 - val_loss: 0.5594\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40c7df",
   "metadata": {},
   "source": [
    "**Add regularization**</br>\n",
    "The training accuarcy is high but validation accuracy is low, which means the model is overfitting. Therefore, add the regularization parameters to the dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "256f299d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Conv1D_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Conv1D_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m96\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m7,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m28,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,548</span> (189.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m48,548\u001b[0m (189.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,388</span> (189.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,388\u001b[0m (189.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 2\n",
    "\n",
    "model2 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a3822fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1059 - loss: 2.3983 - val_accuracy: 0.3333 - val_loss: 1.3945\n",
      "Epoch 2/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4788 - loss: 1.1542 - val_accuracy: 0.3397 - val_loss: 1.3973\n",
      "Epoch 3/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5613 - loss: 1.0279 - val_accuracy: 0.4038 - val_loss: 1.3855\n",
      "Epoch 4/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6128 - loss: 0.9021 - val_accuracy: 0.3782 - val_loss: 1.3831\n",
      "Epoch 5/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6864 - loss: 0.7605 - val_accuracy: 0.3590 - val_loss: 1.3678\n",
      "Epoch 6/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7398 - loss: 0.6536 - val_accuracy: 0.3526 - val_loss: 1.3597\n",
      "Epoch 7/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7480 - loss: 0.6881 - val_accuracy: 0.3590 - val_loss: 1.3238\n",
      "Epoch 8/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7681 - loss: 0.6030 - val_accuracy: 0.3974 - val_loss: 1.2733\n",
      "Epoch 9/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.5135 - val_accuracy: 0.3974 - val_loss: 1.1994\n",
      "Epoch 10/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8029 - loss: 0.5138 - val_accuracy: 0.4615 - val_loss: 1.0725\n",
      "Epoch 11/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8443 - loss: 0.4112 - val_accuracy: 0.5064 - val_loss: 0.9730\n",
      "Epoch 12/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8808 - loss: 0.3518 - val_accuracy: 0.6603 - val_loss: 0.8275\n",
      "Epoch 13/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8410 - loss: 0.3880 - val_accuracy: 0.7500 - val_loss: 0.7155\n",
      "Epoch 14/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8796 - loss: 0.3066 - val_accuracy: 0.7692 - val_loss: 0.6656\n",
      "Epoch 15/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8783 - loss: 0.2938 - val_accuracy: 0.7821 - val_loss: 0.6169\n",
      "Epoch 16/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8992 - loss: 0.2905 - val_accuracy: 0.7692 - val_loss: 0.5636\n",
      "Epoch 17/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9239 - loss: 0.2430 - val_accuracy: 0.8013 - val_loss: 0.5065\n",
      "Epoch 18/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9258 - loss: 0.2246 - val_accuracy: 0.8269 - val_loss: 0.4645\n",
      "Epoch 19/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9568 - loss: 0.1815 - val_accuracy: 0.8205 - val_loss: 0.4630\n",
      "Epoch 20/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9264 - loss: 0.1971 - val_accuracy: 0.8269 - val_loss: 0.4345\n",
      "Epoch 21/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.1734 - val_accuracy: 0.8397 - val_loss: 0.4103\n",
      "Epoch 22/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9363 - loss: 0.1665 - val_accuracy: 0.8397 - val_loss: 0.4110\n",
      "Epoch 23/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9457 - loss: 0.1663 - val_accuracy: 0.8397 - val_loss: 0.4101\n",
      "Epoch 24/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9648 - loss: 0.1208 - val_accuracy: 0.8526 - val_loss: 0.3860\n",
      "Epoch 25/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9589 - loss: 0.1298 - val_accuracy: 0.8269 - val_loss: 0.4235\n",
      "Epoch 26/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9649 - loss: 0.1151 - val_accuracy: 0.8141 - val_loss: 0.4087\n",
      "Epoch 27/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9605 - loss: 0.1061 - val_accuracy: 0.8269 - val_loss: 0.4166\n",
      "Epoch 28/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.1140 - val_accuracy: 0.8205 - val_loss: 0.4260\n",
      "Epoch 29/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9745 - loss: 0.0925 - val_accuracy: 0.8333 - val_loss: 0.4065\n",
      "Epoch 30/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0880 - val_accuracy: 0.8526 - val_loss: 0.3602\n",
      "Epoch 31/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.0971 - val_accuracy: 0.8397 - val_loss: 0.3889\n",
      "Epoch 32/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9781 - loss: 0.0786 - val_accuracy: 0.8462 - val_loss: 0.3722\n",
      "Epoch 33/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.0627 - val_accuracy: 0.8462 - val_loss: 0.3756\n",
      "Epoch 34/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0720 - val_accuracy: 0.8462 - val_loss: 0.3616\n",
      "Epoch 35/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.0597 - val_accuracy: 0.8590 - val_loss: 0.3579\n",
      "Epoch 36/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0451 - val_accuracy: 0.8590 - val_loss: 0.3497\n",
      "Epoch 37/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0471 - val_accuracy: 0.8590 - val_loss: 0.3593\n",
      "Epoch 38/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0455 - val_accuracy: 0.8590 - val_loss: 0.3482\n",
      "Epoch 39/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9767 - loss: 0.0529 - val_accuracy: 0.8718 - val_loss: 0.3406\n",
      "Epoch 40/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0418 - val_accuracy: 0.8590 - val_loss: 0.3666\n",
      "Epoch 41/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0352 - val_accuracy: 0.8590 - val_loss: 0.3745\n",
      "Epoch 42/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0493 - val_accuracy: 0.8590 - val_loss: 0.3638\n",
      "Epoch 43/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0374 - val_accuracy: 0.8718 - val_loss: 0.3839\n",
      "Epoch 44/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0463 - val_accuracy: 0.8718 - val_loss: 0.3446\n",
      "Epoch 45/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0306 - val_accuracy: 0.8526 - val_loss: 0.4164\n",
      "Epoch 46/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0323 - val_accuracy: 0.8654 - val_loss: 0.3527\n",
      "Epoch 47/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0303 - val_accuracy: 0.8654 - val_loss: 0.3741\n",
      "Epoch 48/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0234 - val_accuracy: 0.8654 - val_loss: 0.3752\n",
      "Epoch 49/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0259 - val_accuracy: 0.8590 - val_loss: 0.3673\n",
      "Epoch 50/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0234 - val_accuracy: 0.8590 - val_loss: 0.3948\n",
      "Epoch 51/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0150 - val_accuracy: 0.8654 - val_loss: 0.4286\n",
      "Epoch 52/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0219 - val_accuracy: 0.8590 - val_loss: 0.4236\n",
      "Epoch 53/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0185 - val_accuracy: 0.8718 - val_loss: 0.3857\n",
      "Epoch 54/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0191 - val_accuracy: 0.8782 - val_loss: 0.3804\n",
      "Epoch 55/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0151 - val_accuracy: 0.8910 - val_loss: 0.3518\n",
      "Epoch 56/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0232 - val_accuracy: 0.8718 - val_loss: 0.3920\n",
      "Epoch 57/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0182 - val_accuracy: 0.8846 - val_loss: 0.4050\n",
      "Epoch 58/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0153 - val_accuracy: 0.8846 - val_loss: 0.3956\n",
      "Epoch 59/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0156 - val_accuracy: 0.9038 - val_loss: 0.3595\n",
      "Epoch 60/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0217 - val_accuracy: 0.8782 - val_loss: 0.3996\n",
      "Epoch 61/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0159 - val_accuracy: 0.9103 - val_loss: 0.3329\n",
      "Epoch 62/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0147 - val_accuracy: 0.8846 - val_loss: 0.3812\n",
      "Epoch 63/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.8782 - val_loss: 0.3872\n",
      "Epoch 64/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0070 - val_accuracy: 0.8590 - val_loss: 0.4242\n",
      "Epoch 65/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.8718 - val_loss: 0.4050\n",
      "Epoch 66/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.8782 - val_loss: 0.4328\n",
      "Epoch 67/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0096 - val_accuracy: 0.8654 - val_loss: 0.4139\n",
      "Epoch 68/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.8846 - val_loss: 0.3699\n",
      "Epoch 69/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0137 - val_accuracy: 0.8590 - val_loss: 0.4319\n",
      "Epoch 70/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0302 - val_accuracy: 0.8590 - val_loss: 0.4810\n",
      "Epoch 71/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0133 - val_accuracy: 0.8654 - val_loss: 0.3931\n",
      "Epoch 72/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0163 - val_accuracy: 0.8590 - val_loss: 0.4407\n",
      "Epoch 73/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0048 - val_accuracy: 0.8654 - val_loss: 0.4415\n",
      "Epoch 74/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.8654 - val_loss: 0.4449\n",
      "Epoch 75/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0262 - val_accuracy: 0.8910 - val_loss: 0.3767\n",
      "Epoch 76/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.8654 - val_loss: 0.4266\n",
      "Epoch 77/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.8526 - val_loss: 0.4307\n",
      "Epoch 78/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0150 - val_accuracy: 0.8590 - val_loss: 0.5045\n",
      "Epoch 79/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.8718 - val_loss: 0.4355\n",
      "Epoch 80/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.8718 - val_loss: 0.4781\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d347faf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Conv1D_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Conv1D_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m96\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m7,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m28,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,548</span> (189.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m48,548\u001b[0m (189.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,388</span> (189.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,388\u001b[0m (189.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.2\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.2\n",
    "num = 3\n",
    "\n",
    "model3 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7d27032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3424 - loss: 1.5964 - val_accuracy: 0.3333 - val_loss: 1.4129\n",
      "Epoch 2/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4133 - loss: 1.2501 - val_accuracy: 0.3333 - val_loss: 1.4302\n",
      "Epoch 3/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5802 - loss: 0.9446 - val_accuracy: 0.3333 - val_loss: 1.4318\n",
      "Epoch 4/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6354 - loss: 0.8536 - val_accuracy: 0.3333 - val_loss: 1.4275\n",
      "Epoch 5/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6148 - loss: 0.8333 - val_accuracy: 0.3333 - val_loss: 1.4406\n",
      "Epoch 6/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6980 - loss: 0.7019 - val_accuracy: 0.3333 - val_loss: 1.4518\n",
      "Epoch 7/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7314 - loss: 0.6646 - val_accuracy: 0.3333 - val_loss: 1.4455\n",
      "Epoch 8/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7487 - loss: 0.5920 - val_accuracy: 0.3333 - val_loss: 1.4331\n",
      "Epoch 9/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.5704 - val_accuracy: 0.3333 - val_loss: 1.3599\n",
      "Epoch 10/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8055 - loss: 0.5266 - val_accuracy: 0.3654 - val_loss: 1.2752\n",
      "Epoch 11/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8256 - loss: 0.4782 - val_accuracy: 0.3846 - val_loss: 1.2056\n",
      "Epoch 12/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8153 - loss: 0.4830 - val_accuracy: 0.4679 - val_loss: 1.1053\n",
      "Epoch 13/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8404 - loss: 0.4112 - val_accuracy: 0.5064 - val_loss: 1.0044\n",
      "Epoch 14/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 0.3644 - val_accuracy: 0.5641 - val_loss: 0.9416\n",
      "Epoch 15/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 0.3514 - val_accuracy: 0.6218 - val_loss: 0.8414\n",
      "Epoch 16/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8498 - loss: 0.3745 - val_accuracy: 0.6667 - val_loss: 0.7871\n",
      "Epoch 17/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8760 - loss: 0.3106 - val_accuracy: 0.7115 - val_loss: 0.7285\n",
      "Epoch 18/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8786 - loss: 0.3223 - val_accuracy: 0.7372 - val_loss: 0.6680\n",
      "Epoch 19/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9057 - loss: 0.2781 - val_accuracy: 0.7628 - val_loss: 0.6281\n",
      "Epoch 20/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9129 - loss: 0.2802 - val_accuracy: 0.7756 - val_loss: 0.5926\n",
      "Epoch 21/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9276 - loss: 0.2207 - val_accuracy: 0.7692 - val_loss: 0.5895\n",
      "Epoch 22/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.2251 - val_accuracy: 0.7756 - val_loss: 0.5724\n",
      "Epoch 23/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.1984 - val_accuracy: 0.7756 - val_loss: 0.5559\n",
      "Epoch 24/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.1833 - val_accuracy: 0.7756 - val_loss: 0.5195\n",
      "Epoch 25/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.1463 - val_accuracy: 0.7756 - val_loss: 0.5368\n",
      "Epoch 26/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.1489 - val_accuracy: 0.7821 - val_loss: 0.5318\n",
      "Epoch 27/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9732 - loss: 0.1182 - val_accuracy: 0.7885 - val_loss: 0.5255\n",
      "Epoch 28/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9565 - loss: 0.1270 - val_accuracy: 0.7821 - val_loss: 0.5300\n",
      "Epoch 29/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9703 - loss: 0.1126 - val_accuracy: 0.7821 - val_loss: 0.5208\n",
      "Epoch 30/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9725 - loss: 0.1103 - val_accuracy: 0.7949 - val_loss: 0.4876\n",
      "Epoch 31/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.1149 - val_accuracy: 0.8077 - val_loss: 0.4724\n",
      "Epoch 32/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9624 - loss: 0.1126 - val_accuracy: 0.7885 - val_loss: 0.4983\n",
      "Epoch 33/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9786 - loss: 0.0868 - val_accuracy: 0.7949 - val_loss: 0.5049\n",
      "Epoch 34/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.0810 - val_accuracy: 0.7885 - val_loss: 0.4927\n",
      "Epoch 35/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0644 - val_accuracy: 0.8205 - val_loss: 0.4726\n",
      "Epoch 36/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9728 - loss: 0.0738 - val_accuracy: 0.8462 - val_loss: 0.4528\n",
      "Epoch 37/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9771 - loss: 0.0611 - val_accuracy: 0.8333 - val_loss: 0.4445\n",
      "Epoch 38/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9699 - loss: 0.0960 - val_accuracy: 0.8333 - val_loss: 0.5002\n",
      "Epoch 39/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0562 - val_accuracy: 0.8269 - val_loss: 0.4820\n",
      "Epoch 40/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0501 - val_accuracy: 0.8269 - val_loss: 0.4838\n",
      "Epoch 41/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.0462 - val_accuracy: 0.8205 - val_loss: 0.5037\n",
      "Epoch 42/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0408 - val_accuracy: 0.8333 - val_loss: 0.4864\n",
      "Epoch 43/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0430 - val_accuracy: 0.8397 - val_loss: 0.4728\n",
      "Epoch 44/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.0607 - val_accuracy: 0.8397 - val_loss: 0.4765\n",
      "Epoch 45/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0393 - val_accuracy: 0.8462 - val_loss: 0.4987\n",
      "Epoch 46/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.0570 - val_accuracy: 0.8333 - val_loss: 0.4674\n",
      "Epoch 47/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0412 - val_accuracy: 0.8269 - val_loss: 0.5235\n",
      "Epoch 48/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0347 - val_accuracy: 0.8333 - val_loss: 0.4970\n",
      "Epoch 49/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0308 - val_accuracy: 0.8333 - val_loss: 0.4984\n",
      "Epoch 50/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0260 - val_accuracy: 0.8333 - val_loss: 0.4862\n",
      "Epoch 51/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0251 - val_accuracy: 0.8397 - val_loss: 0.4714\n",
      "Epoch 52/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0248 - val_accuracy: 0.8462 - val_loss: 0.4637\n",
      "Epoch 53/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0187 - val_accuracy: 0.8397 - val_loss: 0.5091\n",
      "Epoch 54/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0204 - val_accuracy: 0.8526 - val_loss: 0.4764\n",
      "Epoch 55/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0281 - val_accuracy: 0.8526 - val_loss: 0.5245\n",
      "Epoch 56/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0228 - val_accuracy: 0.8526 - val_loss: 0.4594\n",
      "Epoch 57/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0281 - val_accuracy: 0.8462 - val_loss: 0.4879\n",
      "Epoch 58/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0218 - val_accuracy: 0.8397 - val_loss: 0.5328\n",
      "Epoch 59/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0222 - val_accuracy: 0.8526 - val_loss: 0.5070\n",
      "Epoch 60/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0163 - val_accuracy: 0.8462 - val_loss: 0.4541\n",
      "Epoch 61/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0142 - val_accuracy: 0.8462 - val_loss: 0.4882\n",
      "Epoch 62/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0147 - val_accuracy: 0.8462 - val_loss: 0.5268\n",
      "Epoch 63/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0212 - val_accuracy: 0.8654 - val_loss: 0.4487\n",
      "Epoch 64/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0118 - val_accuracy: 0.8397 - val_loss: 0.5199\n",
      "Epoch 65/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0186 - val_accuracy: 0.8590 - val_loss: 0.4940\n",
      "Epoch 66/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.8462 - val_loss: 0.4896\n",
      "Epoch 67/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0166 - val_accuracy: 0.8526 - val_loss: 0.4632\n",
      "Epoch 68/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0136 - val_accuracy: 0.8718 - val_loss: 0.4682\n",
      "Epoch 69/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0103 - val_accuracy: 0.8654 - val_loss: 0.4601\n",
      "Epoch 70/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.8718 - val_loss: 0.4483\n",
      "Epoch 71/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.8590 - val_loss: 0.4787\n",
      "Epoch 72/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.8654 - val_loss: 0.4959\n",
      "Epoch 73/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0102 - val_accuracy: 0.8782 - val_loss: 0.4563\n",
      "Epoch 74/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.8654 - val_loss: 0.4684\n",
      "Epoch 75/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0090 - val_accuracy: 0.8654 - val_loss: 0.4794\n",
      "Epoch 76/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.8718 - val_loss: 0.4827\n",
      "Epoch 77/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0086 - val_accuracy: 0.8462 - val_loss: 0.5199\n",
      "Epoch 78/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0113 - val_accuracy: 0.8718 - val_loss: 0.4535\n",
      "Epoch 79/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 0.8782 - val_loss: 0.4560\n",
      "Epoch 80/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0170 - val_accuracy: 0.8590 - val_loss: 0.4907\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568ba75",
   "metadata": {},
   "source": [
    "Adding regularization parameters almost does not improve the validation accuracy very well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f991714c",
   "metadata": {},
   "source": [
    "**Increase the dropout parameter value**<br>\n",
    "This only slightly improve the validation accuracy and damage the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7deb22f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Conv1D_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Conv1D_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m96\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m7,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m28,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,548</span> (189.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m48,548\u001b[0m (189.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,388</span> (189.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,388\u001b[0m (189.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.3,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.3,'relu',0.15\n",
    "num = 4\n",
    "\n",
    "model4 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7435da3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.2615 - loss: 1.7726 - val_accuracy: 0.3141 - val_loss: 1.3319\n",
      "Epoch 2/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4901 - loss: 1.1885 - val_accuracy: 0.3397 - val_loss: 1.2956\n",
      "Epoch 3/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5149 - loss: 1.0710 - val_accuracy: 0.3205 - val_loss: 1.2708\n",
      "Epoch 4/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5763 - loss: 0.9103 - val_accuracy: 0.3269 - val_loss: 1.2508\n",
      "Epoch 5/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5773 - loss: 0.9020 - val_accuracy: 0.3526 - val_loss: 1.2234\n",
      "Epoch 6/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6367 - loss: 0.8755 - val_accuracy: 0.3590 - val_loss: 1.1908\n",
      "Epoch 7/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6348 - loss: 0.7899 - val_accuracy: 0.4295 - val_loss: 1.1448\n",
      "Epoch 8/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6711 - loss: 0.7341 - val_accuracy: 0.4679 - val_loss: 1.0858\n",
      "Epoch 9/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6848 - loss: 0.6980 - val_accuracy: 0.5256 - val_loss: 1.0058\n",
      "Epoch 10/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6956 - loss: 0.6963 - val_accuracy: 0.5641 - val_loss: 0.9312\n",
      "Epoch 11/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7503 - loss: 0.6573 - val_accuracy: 0.6026 - val_loss: 0.8601\n",
      "Epoch 12/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7841 - loss: 0.5691 - val_accuracy: 0.6474 - val_loss: 0.7906\n",
      "Epoch 13/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7792 - loss: 0.5420 - val_accuracy: 0.6667 - val_loss: 0.7385\n",
      "Epoch 14/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.4835 - val_accuracy: 0.7179 - val_loss: 0.6993\n",
      "Epoch 15/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8605 - loss: 0.3987 - val_accuracy: 0.7308 - val_loss: 0.6564\n",
      "Epoch 16/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.4461 - val_accuracy: 0.7436 - val_loss: 0.6378\n",
      "Epoch 17/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8738 - loss: 0.3806 - val_accuracy: 0.7564 - val_loss: 0.5823\n",
      "Epoch 18/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8608 - loss: 0.3608 - val_accuracy: 0.7564 - val_loss: 0.5704\n",
      "Epoch 19/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 0.3547 - val_accuracy: 0.7500 - val_loss: 0.5700\n",
      "Epoch 20/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8871 - loss: 0.3137 - val_accuracy: 0.7500 - val_loss: 0.5684\n",
      "Epoch 21/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.3068 - val_accuracy: 0.7628 - val_loss: 0.5547\n",
      "Epoch 22/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8835 - loss: 0.3020 - val_accuracy: 0.7821 - val_loss: 0.5220\n",
      "Epoch 23/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8637 - loss: 0.3181 - val_accuracy: 0.7949 - val_loss: 0.5170\n",
      "Epoch 24/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8788 - loss: 0.2825 - val_accuracy: 0.8269 - val_loss: 0.4850\n",
      "Epoch 25/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2475 - val_accuracy: 0.8269 - val_loss: 0.4576\n",
      "Epoch 26/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.2087 - val_accuracy: 0.8205 - val_loss: 0.4435\n",
      "Epoch 27/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9267 - loss: 0.1965 - val_accuracy: 0.8077 - val_loss: 0.4416\n",
      "Epoch 28/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9265 - loss: 0.1927 - val_accuracy: 0.8141 - val_loss: 0.4298\n",
      "Epoch 29/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9289 - loss: 0.1951 - val_accuracy: 0.8077 - val_loss: 0.4494\n",
      "Epoch 30/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9451 - loss: 0.1701 - val_accuracy: 0.8397 - val_loss: 0.4239\n",
      "Epoch 31/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.1187 - val_accuracy: 0.8333 - val_loss: 0.4076\n",
      "Epoch 32/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9611 - loss: 0.1249 - val_accuracy: 0.8397 - val_loss: 0.3968\n",
      "Epoch 33/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9591 - loss: 0.1268 - val_accuracy: 0.8462 - val_loss: 0.3786\n",
      "Epoch 34/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9626 - loss: 0.1390 - val_accuracy: 0.8269 - val_loss: 0.3915\n",
      "Epoch 35/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9611 - loss: 0.1246 - val_accuracy: 0.8397 - val_loss: 0.3808\n",
      "Epoch 36/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9507 - loss: 0.1243 - val_accuracy: 0.8462 - val_loss: 0.3943\n",
      "Epoch 37/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.1485 - val_accuracy: 0.8462 - val_loss: 0.3828\n",
      "Epoch 38/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9676 - loss: 0.0989 - val_accuracy: 0.8333 - val_loss: 0.3713\n",
      "Epoch 39/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.0720 - val_accuracy: 0.8462 - val_loss: 0.4011\n",
      "Epoch 40/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9676 - loss: 0.0955 - val_accuracy: 0.8462 - val_loss: 0.3645\n",
      "Epoch 41/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1123 - val_accuracy: 0.8590 - val_loss: 0.3778\n",
      "Epoch 42/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9724 - loss: 0.0763 - val_accuracy: 0.8462 - val_loss: 0.3680\n",
      "Epoch 43/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.0708 - val_accuracy: 0.8590 - val_loss: 0.3391\n",
      "Epoch 44/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.0760 - val_accuracy: 0.8590 - val_loss: 0.3659\n",
      "Epoch 45/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0616 - val_accuracy: 0.8462 - val_loss: 0.3995\n",
      "Epoch 46/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0832 - val_accuracy: 0.8654 - val_loss: 0.3631\n",
      "Epoch 47/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0687 - val_accuracy: 0.8718 - val_loss: 0.3609\n",
      "Epoch 48/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0617 - val_accuracy: 0.8654 - val_loss: 0.3548\n",
      "Epoch 49/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.0493 - val_accuracy: 0.8590 - val_loss: 0.3957\n",
      "Epoch 50/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0442 - val_accuracy: 0.8718 - val_loss: 0.3424\n",
      "Epoch 51/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0425 - val_accuracy: 0.8654 - val_loss: 0.3708\n",
      "Epoch 52/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0432 - val_accuracy: 0.8718 - val_loss: 0.3711\n",
      "Epoch 53/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0515 - val_accuracy: 0.8782 - val_loss: 0.3841\n",
      "Epoch 54/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0414 - val_accuracy: 0.8718 - val_loss: 0.3650\n",
      "Epoch 55/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0337 - val_accuracy: 0.8782 - val_loss: 0.3212\n",
      "Epoch 56/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.0458 - val_accuracy: 0.8654 - val_loss: 0.3397\n",
      "Epoch 57/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0321 - val_accuracy: 0.8654 - val_loss: 0.3240\n",
      "Epoch 58/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0471 - val_accuracy: 0.8590 - val_loss: 0.3698\n",
      "Epoch 59/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0433 - val_accuracy: 0.8590 - val_loss: 0.3427\n",
      "Epoch 60/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0262 - val_accuracy: 0.8718 - val_loss: 0.3293\n",
      "Epoch 61/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0534 - val_accuracy: 0.8782 - val_loss: 0.3068\n",
      "Epoch 62/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0391 - val_accuracy: 0.8718 - val_loss: 0.3210\n",
      "Epoch 63/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0281 - val_accuracy: 0.8718 - val_loss: 0.3528\n",
      "Epoch 64/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0265 - val_accuracy: 0.8782 - val_loss: 0.3304\n",
      "Epoch 65/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0223 - val_accuracy: 0.8654 - val_loss: 0.3288\n",
      "Epoch 66/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0290 - val_accuracy: 0.8718 - val_loss: 0.3696\n",
      "Epoch 67/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0221 - val_accuracy: 0.8718 - val_loss: 0.3518\n",
      "Epoch 68/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0291 - val_accuracy: 0.8718 - val_loss: 0.3675\n",
      "Epoch 69/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0142 - val_accuracy: 0.8590 - val_loss: 0.3546\n",
      "Epoch 70/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0188 - val_accuracy: 0.8782 - val_loss: 0.3209\n",
      "Epoch 71/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0195 - val_accuracy: 0.8782 - val_loss: 0.3229\n",
      "Epoch 72/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.0235 - val_accuracy: 0.8782 - val_loss: 0.3588\n",
      "Epoch 73/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0165 - val_accuracy: 0.8718 - val_loss: 0.3394\n",
      "Epoch 74/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0197 - val_accuracy: 0.8718 - val_loss: 0.3795\n",
      "Epoch 75/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0183 - val_accuracy: 0.8654 - val_loss: 0.3554\n",
      "Epoch 76/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0158 - val_accuracy: 0.8654 - val_loss: 0.3622\n",
      "Epoch 77/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0220 - val_accuracy: 0.8654 - val_loss: 0.3434\n",
      "Epoch 78/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0128 - val_accuracy: 0.8718 - val_loss: 0.3413\n",
      "Epoch 79/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0219 - val_accuracy: 0.8718 - val_loss: 0.3176\n",
      "Epoch 80/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0181 - val_accuracy: 0.8846 - val_loss: 0.3192\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52d1fd",
   "metadata": {},
   "source": [
    "#### Use different parameters\n",
    "\n",
    "**1. Less unit num in Dense layer**<br>\n",
    "Unit number in Dense layer: 128 -> 64, 64 -> 32\n",
    "\n",
    "Lower complexity of the model improves the validation accuracy a bit and decreases the training validation a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b9cf91a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Conv1D_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Conv1D_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m96\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m7,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m14,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,844</span> (108.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,844\u001b[0m (108.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,684</span> (108.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,684\u001b[0m (108.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 64,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 32,0.2,'relu',0.15\n",
    "num = 5\n",
    "\n",
    "model5 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dabc0eb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2145 - loss: 1.8800 - val_accuracy: 0.3462 - val_loss: 1.3787\n",
      "Epoch 2/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4618 - loss: 1.2677 - val_accuracy: 0.3654 - val_loss: 1.3802\n",
      "Epoch 3/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5805 - loss: 1.0024 - val_accuracy: 0.3397 - val_loss: 1.3684\n",
      "Epoch 4/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6127 - loss: 0.9331 - val_accuracy: 0.3269 - val_loss: 1.3444\n",
      "Epoch 5/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6555 - loss: 0.8596 - val_accuracy: 0.3910 - val_loss: 1.3136\n",
      "Epoch 6/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6851 - loss: 0.7084 - val_accuracy: 0.4359 - val_loss: 1.2790\n",
      "Epoch 7/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7119 - loss: 0.6793 - val_accuracy: 0.4295 - val_loss: 1.2306\n",
      "Epoch 8/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7503 - loss: 0.6007 - val_accuracy: 0.4423 - val_loss: 1.1748\n",
      "Epoch 9/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.5507 - val_accuracy: 0.4679 - val_loss: 1.1070\n",
      "Epoch 10/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7574 - loss: 0.5664 - val_accuracy: 0.5256 - val_loss: 1.0063\n",
      "Epoch 11/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7815 - loss: 0.5057 - val_accuracy: 0.5962 - val_loss: 0.9016\n",
      "Epoch 12/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.4501 - val_accuracy: 0.6410 - val_loss: 0.8000\n",
      "Epoch 13/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8336 - loss: 0.4159 - val_accuracy: 0.7115 - val_loss: 0.7037\n",
      "Epoch 14/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8681 - loss: 0.3774 - val_accuracy: 0.7436 - val_loss: 0.6405\n",
      "Epoch 15/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8523 - loss: 0.3680 - val_accuracy: 0.7628 - val_loss: 0.5731\n",
      "Epoch 16/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.3825 - val_accuracy: 0.7885 - val_loss: 0.5204\n",
      "Epoch 17/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8806 - loss: 0.3064 - val_accuracy: 0.8077 - val_loss: 0.4921\n",
      "Epoch 18/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8940 - loss: 0.2926 - val_accuracy: 0.8141 - val_loss: 0.4842\n",
      "Epoch 19/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8693 - loss: 0.3252 - val_accuracy: 0.8269 - val_loss: 0.4343\n",
      "Epoch 20/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8683 - loss: 0.3350 - val_accuracy: 0.8462 - val_loss: 0.4212\n",
      "Epoch 21/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9184 - loss: 0.2518 - val_accuracy: 0.8590 - val_loss: 0.4026\n",
      "Epoch 22/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9266 - loss: 0.2352 - val_accuracy: 0.8590 - val_loss: 0.3896\n",
      "Epoch 23/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9202 - loss: 0.2176 - val_accuracy: 0.8526 - val_loss: 0.3925\n",
      "Epoch 24/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9522 - loss: 0.1892 - val_accuracy: 0.8526 - val_loss: 0.3853\n",
      "Epoch 25/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9361 - loss: 0.1960 - val_accuracy: 0.8654 - val_loss: 0.3595\n",
      "Epoch 26/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9360 - loss: 0.1856 - val_accuracy: 0.8590 - val_loss: 0.3438\n",
      "Epoch 27/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.1645 - val_accuracy: 0.8718 - val_loss: 0.3317\n",
      "Epoch 28/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9410 - loss: 0.1631 - val_accuracy: 0.8782 - val_loss: 0.3409\n",
      "Epoch 29/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9547 - loss: 0.1749 - val_accuracy: 0.8590 - val_loss: 0.3425\n",
      "Epoch 30/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9590 - loss: 0.1418 - val_accuracy: 0.8718 - val_loss: 0.3326\n",
      "Epoch 31/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9598 - loss: 0.1296 - val_accuracy: 0.8654 - val_loss: 0.3337\n",
      "Epoch 32/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.1491 - val_accuracy: 0.8782 - val_loss: 0.3422\n",
      "Epoch 33/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9706 - loss: 0.1045 - val_accuracy: 0.8782 - val_loss: 0.3293\n",
      "Epoch 34/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9720 - loss: 0.1116 - val_accuracy: 0.8782 - val_loss: 0.3206\n",
      "Epoch 35/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9735 - loss: 0.1023 - val_accuracy: 0.8782 - val_loss: 0.3179\n",
      "Epoch 36/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9774 - loss: 0.1024 - val_accuracy: 0.8718 - val_loss: 0.3049\n",
      "Epoch 37/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9722 - loss: 0.0918 - val_accuracy: 0.8846 - val_loss: 0.3155\n",
      "Epoch 38/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.0810 - val_accuracy: 0.8654 - val_loss: 0.3145\n",
      "Epoch 39/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9722 - loss: 0.0940 - val_accuracy: 0.8718 - val_loss: 0.3065\n",
      "Epoch 40/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9724 - loss: 0.0833 - val_accuracy: 0.8782 - val_loss: 0.3095\n",
      "Epoch 41/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.0785 - val_accuracy: 0.8718 - val_loss: 0.3325\n",
      "Epoch 42/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9733 - loss: 0.0963 - val_accuracy: 0.8782 - val_loss: 0.2983\n",
      "Epoch 43/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.0750 - val_accuracy: 0.8846 - val_loss: 0.3143\n",
      "Epoch 44/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.0644 - val_accuracy: 0.8910 - val_loss: 0.3129\n",
      "Epoch 45/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.0724 - val_accuracy: 0.8782 - val_loss: 0.3193\n",
      "Epoch 46/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 0.0650 - val_accuracy: 0.8718 - val_loss: 0.3144\n",
      "Epoch 47/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0562 - val_accuracy: 0.8782 - val_loss: 0.3030\n",
      "Epoch 48/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0598 - val_accuracy: 0.8782 - val_loss: 0.3091\n",
      "Epoch 49/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0399 - val_accuracy: 0.8846 - val_loss: 0.3035\n",
      "Epoch 50/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0481 - val_accuracy: 0.8846 - val_loss: 0.3148\n",
      "Epoch 51/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0495 - val_accuracy: 0.8846 - val_loss: 0.3111\n",
      "Epoch 52/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0597 - val_accuracy: 0.8846 - val_loss: 0.3155\n",
      "Epoch 53/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0708 - val_accuracy: 0.8782 - val_loss: 0.3114\n",
      "Epoch 54/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0408 - val_accuracy: 0.9038 - val_loss: 0.2974\n",
      "Epoch 55/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0599 - val_accuracy: 0.8974 - val_loss: 0.2961\n",
      "Epoch 56/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0425 - val_accuracy: 0.8974 - val_loss: 0.2981\n",
      "Epoch 57/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0448 - val_accuracy: 0.8974 - val_loss: 0.2924\n",
      "Epoch 58/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0372 - val_accuracy: 0.8910 - val_loss: 0.2955\n",
      "Epoch 59/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0403 - val_accuracy: 0.8974 - val_loss: 0.2985\n",
      "Epoch 60/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0388 - val_accuracy: 0.8910 - val_loss: 0.2982\n",
      "Epoch 61/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0388 - val_accuracy: 0.9038 - val_loss: 0.3109\n",
      "Epoch 62/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0239 - val_accuracy: 0.9038 - val_loss: 0.3030\n",
      "Epoch 63/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.0323 - val_accuracy: 0.8910 - val_loss: 0.3207\n",
      "Epoch 64/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0329 - val_accuracy: 0.8974 - val_loss: 0.3331\n",
      "Epoch 65/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0281 - val_accuracy: 0.8974 - val_loss: 0.3190\n",
      "Epoch 66/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0238 - val_accuracy: 0.8974 - val_loss: 0.3265\n",
      "Epoch 67/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0324 - val_accuracy: 0.8974 - val_loss: 0.3271\n",
      "Epoch 68/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0349 - val_accuracy: 0.9103 - val_loss: 0.3210\n",
      "Epoch 69/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0324 - val_accuracy: 0.9038 - val_loss: 0.3160\n",
      "Epoch 70/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.9038 - val_loss: 0.3236\n",
      "Epoch 71/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0224 - val_accuracy: 0.8910 - val_loss: 0.3165\n",
      "Epoch 72/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0311 - val_accuracy: 0.8974 - val_loss: 0.3321\n",
      "Epoch 73/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0145 - val_accuracy: 0.8910 - val_loss: 0.3292\n",
      "Epoch 74/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0154 - val_accuracy: 0.8974 - val_loss: 0.3247\n",
      "Epoch 75/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0206 - val_accuracy: 0.9038 - val_loss: 0.3230\n",
      "Epoch 76/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0217 - val_accuracy: 0.8974 - val_loss: 0.3213\n",
      "Epoch 77/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0167 - val_accuracy: 0.9038 - val_loss: 0.3134\n",
      "Epoch 78/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0148 - val_accuracy: 0.8974 - val_loss: 0.3100\n",
      "Epoch 79/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0210 - val_accuracy: 0.9103 - val_loss: 0.3192\n",
      "Epoch 80/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 0.8910 - val_loss: 0.3420\n"
     ]
    }
   ],
   "source": [
    "history5 = model5.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1efe6",
   "metadata": {},
   "source": [
    "Then, try: <br>\n",
    "Unit number of Dense layers: 128 -> 32, 64 -> 16\n",
    "\n",
    "\n",
    "But this way is unable to improve the model validation accuracy prominently but sacrifices the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d78cb1e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Conv1D_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Conv1D_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m96\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m7,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m7,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m68\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,028</span> (74.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,028\u001b[0m (74.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,868</span> (73.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,868\u001b[0m (73.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 32,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 16,0.2,'relu',0.15\n",
    "num = 5\n",
    "\n",
    "model5 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,                            \n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,                               \n",
    "                        d1,dr1,da1,r1,                        \n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c642b5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2600 - loss: 2.3453 - val_accuracy: 0.3205 - val_loss: 1.3966\n",
      "Epoch 2/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3696 - loss: 1.5455 - val_accuracy: 0.3013 - val_loss: 1.4154\n",
      "Epoch 3/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3885 - loss: 1.4115 - val_accuracy: 0.1923 - val_loss: 1.4393\n",
      "Epoch 4/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5291 - loss: 1.2042 - val_accuracy: 0.0769 - val_loss: 1.4592\n",
      "Epoch 5/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5479 - loss: 1.0899 - val_accuracy: 0.0513 - val_loss: 1.4592\n",
      "Epoch 6/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5427 - loss: 1.0875 - val_accuracy: 0.0641 - val_loss: 1.4481\n",
      "Epoch 7/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6176 - loss: 0.9740 - val_accuracy: 0.1667 - val_loss: 1.3832\n",
      "Epoch 8/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6575 - loss: 0.8512 - val_accuracy: 0.3590 - val_loss: 1.3060\n",
      "Epoch 9/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6345 - loss: 0.8986 - val_accuracy: 0.4551 - val_loss: 1.2284\n",
      "Epoch 10/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.8103 - val_accuracy: 0.5385 - val_loss: 1.1457\n",
      "Epoch 11/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7241 - loss: 0.7673 - val_accuracy: 0.5962 - val_loss: 1.0656\n",
      "Epoch 12/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6654 - loss: 0.8095 - val_accuracy: 0.6603 - val_loss: 0.9839\n",
      "Epoch 13/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.7096 - val_accuracy: 0.6923 - val_loss: 0.9153\n",
      "Epoch 14/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6747 - loss: 0.7263 - val_accuracy: 0.7372 - val_loss: 0.8446\n",
      "Epoch 15/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7405 - loss: 0.6872 - val_accuracy: 0.7436 - val_loss: 0.7675\n",
      "Epoch 16/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7993 - loss: 0.5827 - val_accuracy: 0.7436 - val_loss: 0.7053\n",
      "Epoch 17/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7678 - loss: 0.6039 - val_accuracy: 0.7500 - val_loss: 0.6767\n",
      "Epoch 18/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7771 - loss: 0.5980 - val_accuracy: 0.7564 - val_loss: 0.6467\n",
      "Epoch 19/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.6039 - val_accuracy: 0.7692 - val_loss: 0.6312\n",
      "Epoch 20/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.5298 - val_accuracy: 0.7756 - val_loss: 0.6118\n",
      "Epoch 21/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8106 - loss: 0.4981 - val_accuracy: 0.7756 - val_loss: 0.5895\n",
      "Epoch 22/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.5550 - val_accuracy: 0.7885 - val_loss: 0.5734\n",
      "Epoch 23/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8367 - loss: 0.4252 - val_accuracy: 0.7949 - val_loss: 0.5652\n",
      "Epoch 24/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8172 - loss: 0.4878 - val_accuracy: 0.8013 - val_loss: 0.5556\n",
      "Epoch 25/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8812 - loss: 0.3767 - val_accuracy: 0.8269 - val_loss: 0.5355\n",
      "Epoch 26/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.4253 - val_accuracy: 0.7885 - val_loss: 0.5287\n",
      "Epoch 27/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8728 - loss: 0.3642 - val_accuracy: 0.8077 - val_loss: 0.5123\n",
      "Epoch 28/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8636 - loss: 0.3403 - val_accuracy: 0.8077 - val_loss: 0.5007\n",
      "Epoch 29/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.3330 - val_accuracy: 0.8333 - val_loss: 0.4879\n",
      "Epoch 30/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8554 - loss: 0.3616 - val_accuracy: 0.8077 - val_loss: 0.4796\n",
      "Epoch 31/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8675 - loss: 0.3631 - val_accuracy: 0.8141 - val_loss: 0.4692\n",
      "Epoch 32/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.2838 - val_accuracy: 0.8333 - val_loss: 0.4618\n",
      "Epoch 33/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9073 - loss: 0.2862 - val_accuracy: 0.8269 - val_loss: 0.4547\n",
      "Epoch 34/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.2633 - val_accuracy: 0.8397 - val_loss: 0.4470\n",
      "Epoch 35/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9068 - loss: 0.2638 - val_accuracy: 0.8141 - val_loss: 0.4584\n",
      "Epoch 36/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9146 - loss: 0.2308 - val_accuracy: 0.8269 - val_loss: 0.4416\n",
      "Epoch 37/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9102 - loss: 0.2319 - val_accuracy: 0.8333 - val_loss: 0.4436\n",
      "Epoch 38/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9399 - loss: 0.2081 - val_accuracy: 0.8205 - val_loss: 0.4350\n",
      "Epoch 39/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9165 - loss: 0.2383 - val_accuracy: 0.8397 - val_loss: 0.4296\n",
      "Epoch 40/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2291 - val_accuracy: 0.8397 - val_loss: 0.4188\n",
      "Epoch 41/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9315 - loss: 0.1872 - val_accuracy: 0.8462 - val_loss: 0.4133\n",
      "Epoch 42/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.1865 - val_accuracy: 0.8397 - val_loss: 0.4068\n",
      "Epoch 43/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9026 - loss: 0.2280 - val_accuracy: 0.8397 - val_loss: 0.4053\n",
      "Epoch 44/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9366 - loss: 0.1851 - val_accuracy: 0.8397 - val_loss: 0.4066\n",
      "Epoch 45/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.1626 - val_accuracy: 0.8462 - val_loss: 0.3930\n",
      "Epoch 46/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.1424 - val_accuracy: 0.8462 - val_loss: 0.3961\n",
      "Epoch 47/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1439 - val_accuracy: 0.8333 - val_loss: 0.4081\n",
      "Epoch 48/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1463 - val_accuracy: 0.8654 - val_loss: 0.3849\n",
      "Epoch 49/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1431 - val_accuracy: 0.8654 - val_loss: 0.3808\n",
      "Epoch 50/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1214 - val_accuracy: 0.8526 - val_loss: 0.3751\n",
      "Epoch 51/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.1174 - val_accuracy: 0.8590 - val_loss: 0.3682\n",
      "Epoch 52/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1316 - val_accuracy: 0.8718 - val_loss: 0.3539\n",
      "Epoch 53/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.1350 - val_accuracy: 0.8526 - val_loss: 0.3724\n",
      "Epoch 54/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9450 - loss: 0.1486 - val_accuracy: 0.8718 - val_loss: 0.3417\n",
      "Epoch 55/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9430 - loss: 0.1444 - val_accuracy: 0.8654 - val_loss: 0.3474\n",
      "Epoch 56/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1470 - val_accuracy: 0.8654 - val_loss: 0.3522\n",
      "Epoch 57/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.1016 - val_accuracy: 0.8718 - val_loss: 0.3485\n",
      "Epoch 58/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.1146 - val_accuracy: 0.8846 - val_loss: 0.3364\n",
      "Epoch 59/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.0988 - val_accuracy: 0.8846 - val_loss: 0.3301\n",
      "Epoch 60/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0874 - val_accuracy: 0.8910 - val_loss: 0.3419\n",
      "Epoch 61/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.1117 - val_accuracy: 0.8846 - val_loss: 0.3465\n",
      "Epoch 62/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1180 - val_accuracy: 0.8846 - val_loss: 0.3307\n",
      "Epoch 63/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0827 - val_accuracy: 0.8846 - val_loss: 0.3145\n",
      "Epoch 64/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1094 - val_accuracy: 0.8782 - val_loss: 0.3216\n",
      "Epoch 65/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.0813 - val_accuracy: 0.8782 - val_loss: 0.3069\n",
      "Epoch 66/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0774 - val_accuracy: 0.8782 - val_loss: 0.3380\n",
      "Epoch 67/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1044 - val_accuracy: 0.8846 - val_loss: 0.3132\n",
      "Epoch 68/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.0825 - val_accuracy: 0.8910 - val_loss: 0.2924\n",
      "Epoch 69/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0616 - val_accuracy: 0.8974 - val_loss: 0.2934\n",
      "Epoch 70/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9681 - loss: 0.0888 - val_accuracy: 0.8910 - val_loss: 0.3141\n",
      "Epoch 71/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.0803 - val_accuracy: 0.8974 - val_loss: 0.3165\n",
      "Epoch 72/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0609 - val_accuracy: 0.9103 - val_loss: 0.3062\n",
      "Epoch 73/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.0802 - val_accuracy: 0.9038 - val_loss: 0.3048\n",
      "Epoch 74/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0746 - val_accuracy: 0.8974 - val_loss: 0.3140\n",
      "Epoch 75/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.0890 - val_accuracy: 0.8974 - val_loss: 0.3165\n",
      "Epoch 76/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0683 - val_accuracy: 0.9167 - val_loss: 0.2942\n",
      "Epoch 77/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9783 - loss: 0.0754 - val_accuracy: 0.8846 - val_loss: 0.3136\n",
      "Epoch 78/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0503 - val_accuracy: 0.8910 - val_loss: 0.3037\n",
      "Epoch 79/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.0729 - val_accuracy: 0.9038 - val_loss: 0.2937\n",
      "Epoch 80/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0583 - val_accuracy: 0.8974 - val_loss: 0.3029\n"
     ]
    }
   ],
   "source": [
    "history5 = model5.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c949242",
   "metadata": {},
   "source": [
    "**Different num of filters and kernel size**<br>\n",
    "- f1,k1: 16,5 -> 8,3\n",
    "- f2,k2: 32,7 -> 16,5\n",
    "- f3,k3: 32,7 -> 16,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0357b4fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Conv1D_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Conv1D_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m14,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,124</span> (98.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,124\u001b[0m (98.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,044</span> (97.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,044\u001b[0m (97.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> (320.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m80\u001b[0m (320.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1,k1,a1 = 8,3,'relu'\n",
    "f2,k2,a2 = 16,5,'relu'\n",
    "f3,k3,a3 = 16,5,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 6\n",
    "\n",
    "model6 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00148418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.2801 - loss: 1.8106 - val_accuracy: 0.3333 - val_loss: 1.3702\n",
      "Epoch 2/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3786 - loss: 1.4311 - val_accuracy: 0.3269 - val_loss: 1.3547\n",
      "Epoch 3/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5253 - loss: 1.1332 - val_accuracy: 0.3397 - val_loss: 1.3371\n",
      "Epoch 4/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5072 - loss: 1.0913 - val_accuracy: 0.4167 - val_loss: 1.3062\n",
      "Epoch 5/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5829 - loss: 0.9948 - val_accuracy: 0.4744 - val_loss: 1.2650\n",
      "Epoch 6/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5915 - loss: 0.9654 - val_accuracy: 0.5256 - val_loss: 1.2169\n",
      "Epoch 7/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5813 - loss: 0.8899 - val_accuracy: 0.5256 - val_loss: 1.1665\n",
      "Epoch 8/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5879 - loss: 0.8773 - val_accuracy: 0.5192 - val_loss: 1.1158\n",
      "Epoch 9/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6232 - loss: 0.8676 - val_accuracy: 0.5000 - val_loss: 1.0731\n",
      "Epoch 10/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6563 - loss: 0.7846 - val_accuracy: 0.5000 - val_loss: 1.0284\n",
      "Epoch 11/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6545 - loss: 0.8112 - val_accuracy: 0.5385 - val_loss: 0.9875\n",
      "Epoch 12/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7174 - loss: 0.6759 - val_accuracy: 0.5577 - val_loss: 0.9470\n",
      "Epoch 13/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6469 - loss: 0.7511 - val_accuracy: 0.5705 - val_loss: 0.9183\n",
      "Epoch 14/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6609 - loss: 0.7306 - val_accuracy: 0.5897 - val_loss: 0.8920\n",
      "Epoch 15/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6838 - loss: 0.7210 - val_accuracy: 0.5833 - val_loss: 0.8773\n",
      "Epoch 16/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6787 - loss: 0.6973 - val_accuracy: 0.6218 - val_loss: 0.8567\n",
      "Epoch 17/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7154 - loss: 0.6482 - val_accuracy: 0.6154 - val_loss: 0.8355\n",
      "Epoch 18/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7103 - loss: 0.6320 - val_accuracy: 0.6218 - val_loss: 0.8295\n",
      "Epoch 19/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7177 - loss: 0.6113 - val_accuracy: 0.6282 - val_loss: 0.8150\n",
      "Epoch 20/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7500 - loss: 0.5587 - val_accuracy: 0.6474 - val_loss: 0.8085\n",
      "Epoch 21/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.5684 - val_accuracy: 0.6731 - val_loss: 0.7825\n",
      "Epoch 22/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7633 - loss: 0.5542 - val_accuracy: 0.6603 - val_loss: 0.7818\n",
      "Epoch 23/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7877 - loss: 0.4953 - val_accuracy: 0.6667 - val_loss: 0.7824\n",
      "Epoch 24/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7518 - loss: 0.5508 - val_accuracy: 0.6667 - val_loss: 0.7743\n",
      "Epoch 25/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7558 - loss: 0.5358 - val_accuracy: 0.6603 - val_loss: 0.7675\n",
      "Epoch 26/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.5377 - val_accuracy: 0.6603 - val_loss: 0.7595\n",
      "Epoch 27/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.4748 - val_accuracy: 0.6795 - val_loss: 0.7640\n",
      "Epoch 28/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8069 - loss: 0.4470 - val_accuracy: 0.6923 - val_loss: 0.7451\n",
      "Epoch 29/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8615 - loss: 0.4030 - val_accuracy: 0.6795 - val_loss: 0.7429\n",
      "Epoch 30/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.4385 - val_accuracy: 0.7051 - val_loss: 0.7367\n",
      "Epoch 31/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4468 - val_accuracy: 0.7051 - val_loss: 0.7385\n",
      "Epoch 32/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7544 - loss: 0.4553 - val_accuracy: 0.7051 - val_loss: 0.7287\n",
      "Epoch 33/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8021 - loss: 0.4516 - val_accuracy: 0.6987 - val_loss: 0.7325\n",
      "Epoch 34/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8195 - loss: 0.4334 - val_accuracy: 0.6987 - val_loss: 0.7165\n",
      "Epoch 35/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7986 - loss: 0.4674 - val_accuracy: 0.7244 - val_loss: 0.7133\n",
      "Epoch 36/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7986 - loss: 0.3968 - val_accuracy: 0.7436 - val_loss: 0.7165\n",
      "Epoch 37/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8300 - loss: 0.4093 - val_accuracy: 0.7308 - val_loss: 0.7129\n",
      "Epoch 38/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.3982 - val_accuracy: 0.7179 - val_loss: 0.7061\n",
      "Epoch 39/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8742 - loss: 0.3294 - val_accuracy: 0.7308 - val_loss: 0.7052\n",
      "Epoch 40/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8509 - loss: 0.3756 - val_accuracy: 0.7308 - val_loss: 0.6905\n",
      "Epoch 41/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8620 - loss: 0.3411 - val_accuracy: 0.7436 - val_loss: 0.6923\n",
      "Epoch 42/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8520 - loss: 0.3307 - val_accuracy: 0.7500 - val_loss: 0.6903\n",
      "Epoch 43/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8901 - loss: 0.2904 - val_accuracy: 0.7436 - val_loss: 0.6815\n",
      "Epoch 44/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8734 - loss: 0.3033 - val_accuracy: 0.7564 - val_loss: 0.6685\n",
      "Epoch 45/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.2928 - val_accuracy: 0.7500 - val_loss: 0.6822\n",
      "Epoch 46/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.2866 - val_accuracy: 0.7500 - val_loss: 0.6732\n",
      "Epoch 47/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.2681 - val_accuracy: 0.7628 - val_loss: 0.6666\n",
      "Epoch 48/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.2922 - val_accuracy: 0.7756 - val_loss: 0.6474\n",
      "Epoch 49/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9091 - loss: 0.2374 - val_accuracy: 0.7692 - val_loss: 0.6403\n",
      "Epoch 50/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2659 - val_accuracy: 0.7628 - val_loss: 0.6489\n",
      "Epoch 51/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8794 - loss: 0.2756 - val_accuracy: 0.7756 - val_loss: 0.6391\n",
      "Epoch 52/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.2153 - val_accuracy: 0.7821 - val_loss: 0.6514\n",
      "Epoch 53/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2288 - val_accuracy: 0.7692 - val_loss: 0.6254\n",
      "Epoch 54/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.2036 - val_accuracy: 0.7756 - val_loss: 0.6259\n",
      "Epoch 55/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2227 - val_accuracy: 0.7756 - val_loss: 0.6220\n",
      "Epoch 56/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.1674 - val_accuracy: 0.7692 - val_loss: 0.6314\n",
      "Epoch 57/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1693 - val_accuracy: 0.7821 - val_loss: 0.6085\n",
      "Epoch 58/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.1866 - val_accuracy: 0.7756 - val_loss: 0.6162\n",
      "Epoch 59/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1666 - val_accuracy: 0.7756 - val_loss: 0.6220\n",
      "Epoch 60/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1792 - val_accuracy: 0.7756 - val_loss: 0.6222\n",
      "Epoch 61/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.2012 - val_accuracy: 0.7821 - val_loss: 0.6133\n",
      "Epoch 62/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1462 - val_accuracy: 0.7756 - val_loss: 0.5948\n",
      "Epoch 63/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9355 - loss: 0.1655 - val_accuracy: 0.7692 - val_loss: 0.5992\n",
      "Epoch 64/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1617 - val_accuracy: 0.7692 - val_loss: 0.6011\n",
      "Epoch 65/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1458 - val_accuracy: 0.7756 - val_loss: 0.5878\n",
      "Epoch 66/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.1379 - val_accuracy: 0.7692 - val_loss: 0.5928\n",
      "Epoch 67/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.1325 - val_accuracy: 0.7885 - val_loss: 0.5975\n",
      "Epoch 68/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1249 - val_accuracy: 0.7756 - val_loss: 0.5996\n",
      "Epoch 69/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.1191 - val_accuracy: 0.7821 - val_loss: 0.5830\n",
      "Epoch 70/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1323 - val_accuracy: 0.7949 - val_loss: 0.5997\n",
      "Epoch 71/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1144 - val_accuracy: 0.7821 - val_loss: 0.5994\n",
      "Epoch 72/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1136 - val_accuracy: 0.7692 - val_loss: 0.5749\n",
      "Epoch 73/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.1224 - val_accuracy: 0.7885 - val_loss: 0.5656\n",
      "Epoch 74/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9476 - loss: 0.1204 - val_accuracy: 0.8013 - val_loss: 0.5713\n",
      "Epoch 75/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.0826 - val_accuracy: 0.7756 - val_loss: 0.5828\n",
      "Epoch 76/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.0883 - val_accuracy: 0.7692 - val_loss: 0.6016\n",
      "Epoch 77/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.0799 - val_accuracy: 0.7821 - val_loss: 0.5985\n",
      "Epoch 78/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0820 - val_accuracy: 0.8077 - val_loss: 0.5617\n",
      "Epoch 79/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9790 - loss: 0.0759 - val_accuracy: 0.7885 - val_loss: 0.5668\n",
      "Epoch 80/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9783 - loss: 0.0824 - val_accuracy: 0.8077 - val_loss: 0.5719\n"
     ]
    }
   ],
   "source": [
    "history6 = model6.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd33b1e6",
   "metadata": {},
   "source": [
    "- f1,k1: 16,5 -> 8,3\n",
    "- f2,k2: 32,7 -> 16,5\n",
    "- f3,k3: 32,7 -> 32,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb3a20cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Conv1D_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Conv1D_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m28,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,844</span> (163.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,844\u001b[0m (163.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,732</span> (163.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,732\u001b[0m (163.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> (448.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m112\u001b[0m (448.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1,k1,a1 = 8,3,'relu'\n",
    "f2,k2,a2 = 16,5,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 7\n",
    "\n",
    "model7 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd93420f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.2924 - loss: 1.6772 - val_accuracy: 0.5128 - val_loss: 1.3343\n",
      "Epoch 2/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4752 - loss: 1.2072 - val_accuracy: 0.4744 - val_loss: 1.2830\n",
      "Epoch 3/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5713 - loss: 0.9575 - val_accuracy: 0.4231 - val_loss: 1.2395\n",
      "Epoch 4/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6064 - loss: 0.9396 - val_accuracy: 0.3846 - val_loss: 1.2001\n",
      "Epoch 5/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6129 - loss: 0.8728 - val_accuracy: 0.3910 - val_loss: 1.1669\n",
      "Epoch 6/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6239 - loss: 0.8318 - val_accuracy: 0.4423 - val_loss: 1.1347\n",
      "Epoch 7/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7506 - loss: 0.6713 - val_accuracy: 0.4295 - val_loss: 1.1047\n",
      "Epoch 8/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7104 - loss: 0.6700 - val_accuracy: 0.5064 - val_loss: 1.0577\n",
      "Epoch 9/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7458 - loss: 0.6132 - val_accuracy: 0.5192 - val_loss: 1.0040\n",
      "Epoch 10/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7549 - loss: 0.5954 - val_accuracy: 0.5577 - val_loss: 0.9355\n",
      "Epoch 11/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7751 - loss: 0.5378 - val_accuracy: 0.5833 - val_loss: 0.8784\n",
      "Epoch 12/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7774 - loss: 0.5427 - val_accuracy: 0.6090 - val_loss: 0.8192\n",
      "Epoch 13/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.4942 - val_accuracy: 0.6474 - val_loss: 0.7544\n",
      "Epoch 14/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8130 - loss: 0.4900 - val_accuracy: 0.6859 - val_loss: 0.6933\n",
      "Epoch 15/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 0.4001 - val_accuracy: 0.7051 - val_loss: 0.6465\n",
      "Epoch 16/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.4602 - val_accuracy: 0.7179 - val_loss: 0.6171\n",
      "Epoch 17/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8838 - loss: 0.3268 - val_accuracy: 0.6987 - val_loss: 0.6115\n",
      "Epoch 18/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8777 - loss: 0.3644 - val_accuracy: 0.7115 - val_loss: 0.5841\n",
      "Epoch 19/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8925 - loss: 0.3202 - val_accuracy: 0.7179 - val_loss: 0.5694\n",
      "Epoch 20/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 0.3112 - val_accuracy: 0.7308 - val_loss: 0.5538\n",
      "Epoch 21/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8629 - loss: 0.3282 - val_accuracy: 0.7179 - val_loss: 0.5633\n",
      "Epoch 22/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9242 - loss: 0.2471 - val_accuracy: 0.7244 - val_loss: 0.5626\n",
      "Epoch 23/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8919 - loss: 0.2802 - val_accuracy: 0.7308 - val_loss: 0.5391\n",
      "Epoch 24/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9243 - loss: 0.2347 - val_accuracy: 0.7372 - val_loss: 0.5397\n",
      "Epoch 25/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.2234 - val_accuracy: 0.7372 - val_loss: 0.5242\n",
      "Epoch 26/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9136 - loss: 0.2286 - val_accuracy: 0.7500 - val_loss: 0.5180\n",
      "Epoch 27/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9075 - loss: 0.2269 - val_accuracy: 0.7372 - val_loss: 0.5378\n",
      "Epoch 28/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2091 - val_accuracy: 0.7308 - val_loss: 0.5268\n",
      "Epoch 29/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9487 - loss: 0.1894 - val_accuracy: 0.7372 - val_loss: 0.5436\n",
      "Epoch 30/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9286 - loss: 0.2225 - val_accuracy: 0.7564 - val_loss: 0.5153\n",
      "Epoch 31/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9349 - loss: 0.1782 - val_accuracy: 0.7500 - val_loss: 0.5205\n",
      "Epoch 32/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9600 - loss: 0.1465 - val_accuracy: 0.7500 - val_loss: 0.5100\n",
      "Epoch 33/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9519 - loss: 0.1573 - val_accuracy: 0.7628 - val_loss: 0.5036\n",
      "Epoch 34/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9430 - loss: 0.1683 - val_accuracy: 0.7628 - val_loss: 0.4933\n",
      "Epoch 35/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9304 - loss: 0.1748 - val_accuracy: 0.7692 - val_loss: 0.4772\n",
      "Epoch 36/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9611 - loss: 0.1291 - val_accuracy: 0.7628 - val_loss: 0.4719\n",
      "Epoch 37/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9719 - loss: 0.1180 - val_accuracy: 0.7628 - val_loss: 0.4856\n",
      "Epoch 38/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9616 - loss: 0.1251 - val_accuracy: 0.7628 - val_loss: 0.4869\n",
      "Epoch 39/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9532 - loss: 0.1531 - val_accuracy: 0.7692 - val_loss: 0.4867\n",
      "Epoch 40/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9703 - loss: 0.1090 - val_accuracy: 0.7628 - val_loss: 0.4908\n",
      "Epoch 41/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.1081 - val_accuracy: 0.7628 - val_loss: 0.4895\n",
      "Epoch 42/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.1063 - val_accuracy: 0.7436 - val_loss: 0.5068\n",
      "Epoch 43/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.1051 - val_accuracy: 0.7692 - val_loss: 0.4739\n",
      "Epoch 44/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9632 - loss: 0.0999 - val_accuracy: 0.7564 - val_loss: 0.4662\n",
      "Epoch 45/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.1080 - val_accuracy: 0.7628 - val_loss: 0.4630\n",
      "Epoch 46/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9551 - loss: 0.1100 - val_accuracy: 0.7756 - val_loss: 0.4618\n",
      "Epoch 47/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.0926 - val_accuracy: 0.7821 - val_loss: 0.4597\n",
      "Epoch 48/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9736 - loss: 0.0945 - val_accuracy: 0.7756 - val_loss: 0.4625\n",
      "Epoch 49/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0534 - val_accuracy: 0.7885 - val_loss: 0.4682\n",
      "Epoch 50/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.0823 - val_accuracy: 0.7821 - val_loss: 0.4635\n",
      "Epoch 51/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9715 - loss: 0.0743 - val_accuracy: 0.7756 - val_loss: 0.4608\n",
      "Epoch 52/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0673 - val_accuracy: 0.7692 - val_loss: 0.4883\n",
      "Epoch 53/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0679 - val_accuracy: 0.7692 - val_loss: 0.4867\n",
      "Epoch 54/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.0679 - val_accuracy: 0.7756 - val_loss: 0.4608\n",
      "Epoch 55/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.0601 - val_accuracy: 0.7821 - val_loss: 0.4586\n",
      "Epoch 56/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0711 - val_accuracy: 0.7564 - val_loss: 0.4799\n",
      "Epoch 57/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0618 - val_accuracy: 0.7756 - val_loss: 0.4901\n",
      "Epoch 58/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9865 - loss: 0.0480 - val_accuracy: 0.7821 - val_loss: 0.4812\n",
      "Epoch 59/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0566 - val_accuracy: 0.7756 - val_loss: 0.4757\n",
      "Epoch 60/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0544 - val_accuracy: 0.7756 - val_loss: 0.4779\n",
      "Epoch 61/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0684 - val_accuracy: 0.7756 - val_loss: 0.4863\n",
      "Epoch 62/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0475 - val_accuracy: 0.7949 - val_loss: 0.4768\n",
      "Epoch 63/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0421 - val_accuracy: 0.7756 - val_loss: 0.4839\n",
      "Epoch 64/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0423 - val_accuracy: 0.7821 - val_loss: 0.4749\n",
      "Epoch 65/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0429 - val_accuracy: 0.7885 - val_loss: 0.4845\n",
      "Epoch 66/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0421 - val_accuracy: 0.7821 - val_loss: 0.4860\n",
      "Epoch 67/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0402 - val_accuracy: 0.7756 - val_loss: 0.4947\n",
      "Epoch 68/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0346 - val_accuracy: 0.7821 - val_loss: 0.5040\n",
      "Epoch 69/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0263 - val_accuracy: 0.7821 - val_loss: 0.4986\n",
      "Epoch 70/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0316 - val_accuracy: 0.7885 - val_loss: 0.5348\n",
      "Epoch 71/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0275 - val_accuracy: 0.7821 - val_loss: 0.5177\n",
      "Epoch 72/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0269 - val_accuracy: 0.7756 - val_loss: 0.5414\n",
      "Epoch 73/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0223 - val_accuracy: 0.7885 - val_loss: 0.5448\n",
      "Epoch 74/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9895 - loss: 0.0326 - val_accuracy: 0.7885 - val_loss: 0.5011\n",
      "Epoch 75/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0255 - val_accuracy: 0.7949 - val_loss: 0.5003\n",
      "Epoch 76/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0288 - val_accuracy: 0.7885 - val_loss: 0.5087\n",
      "Epoch 77/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0338 - val_accuracy: 0.8013 - val_loss: 0.5040\n",
      "Epoch 78/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0225 - val_accuracy: 0.7949 - val_loss: 0.5146\n",
      "Epoch 79/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0206 - val_accuracy: 0.7949 - val_loss: 0.5224\n",
      "Epoch 80/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0293 - val_accuracy: 0.7821 - val_loss: 0.5217\n"
     ]
    }
   ],
   "source": [
    "history7 = model7.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d1c7f",
   "metadata": {},
   "source": [
    "- f1,k1: 16,5 -> 16,5\n",
    "- f2,k2: 32,7 -> 16,5\n",
    "- f3,k3: 32,7 -> 32,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2bf3529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Conv1D_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Conv1D_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m96\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m28,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,580</span> (166.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,580\u001b[0m (166.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,452</span> (165.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,452\u001b[0m (165.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 16,5,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 8\n",
    "\n",
    "model8 = modelBuilder3L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5549275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3781 - loss: 1.2576 - val_accuracy: 0.3333 - val_loss: 1.3529\n",
      "Epoch 2/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5250 - loss: 0.9906 - val_accuracy: 0.3333 - val_loss: 1.3219\n",
      "Epoch 3/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5943 - loss: 0.9270 - val_accuracy: 0.3333 - val_loss: 1.2938\n",
      "Epoch 4/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6574 - loss: 0.7906 - val_accuracy: 0.3333 - val_loss: 1.2705\n",
      "Epoch 5/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6851 - loss: 0.7412 - val_accuracy: 0.3526 - val_loss: 1.2460\n",
      "Epoch 6/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7004 - loss: 0.7107 - val_accuracy: 0.3654 - val_loss: 1.2173\n",
      "Epoch 7/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7523 - loss: 0.6055 - val_accuracy: 0.3782 - val_loss: 1.1783\n",
      "Epoch 8/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7502 - loss: 0.6148 - val_accuracy: 0.4038 - val_loss: 1.1413\n",
      "Epoch 9/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.5375 - val_accuracy: 0.4295 - val_loss: 1.0952\n",
      "Epoch 10/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7694 - loss: 0.5908 - val_accuracy: 0.4872 - val_loss: 1.0351\n",
      "Epoch 11/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8000 - loss: 0.5157 - val_accuracy: 0.5256 - val_loss: 0.9805\n",
      "Epoch 12/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.4573 - val_accuracy: 0.5449 - val_loss: 0.9338\n",
      "Epoch 13/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8296 - loss: 0.4408 - val_accuracy: 0.5705 - val_loss: 0.8943\n",
      "Epoch 14/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8655 - loss: 0.4063 - val_accuracy: 0.5962 - val_loss: 0.8501\n",
      "Epoch 15/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8800 - loss: 0.3494 - val_accuracy: 0.6410 - val_loss: 0.7787\n",
      "Epoch 16/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8702 - loss: 0.3530 - val_accuracy: 0.6474 - val_loss: 0.7623\n",
      "Epoch 17/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8523 - loss: 0.3780 - val_accuracy: 0.6667 - val_loss: 0.7523\n",
      "Epoch 18/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8782 - loss: 0.3080 - val_accuracy: 0.7051 - val_loss: 0.6819\n",
      "Epoch 19/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8968 - loss: 0.3094 - val_accuracy: 0.6923 - val_loss: 0.6753\n",
      "Epoch 20/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2742 - val_accuracy: 0.7115 - val_loss: 0.6393\n",
      "Epoch 21/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8919 - loss: 0.2284 - val_accuracy: 0.7179 - val_loss: 0.6409\n",
      "Epoch 22/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.2268 - val_accuracy: 0.7179 - val_loss: 0.6118\n",
      "Epoch 23/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9226 - loss: 0.2056 - val_accuracy: 0.7308 - val_loss: 0.6104\n",
      "Epoch 24/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9303 - loss: 0.1991 - val_accuracy: 0.7436 - val_loss: 0.5956\n",
      "Epoch 25/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9221 - loss: 0.2250 - val_accuracy: 0.7692 - val_loss: 0.5647\n",
      "Epoch 26/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9297 - loss: 0.1951 - val_accuracy: 0.7949 - val_loss: 0.5655\n",
      "Epoch 27/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.1716 - val_accuracy: 0.7628 - val_loss: 0.5641\n",
      "Epoch 28/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.1743 - val_accuracy: 0.7949 - val_loss: 0.5350\n",
      "Epoch 29/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.1472 - val_accuracy: 0.7885 - val_loss: 0.5635\n",
      "Epoch 30/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9635 - loss: 0.1398 - val_accuracy: 0.7692 - val_loss: 0.5753\n",
      "Epoch 31/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9418 - loss: 0.1513 - val_accuracy: 0.7949 - val_loss: 0.5495\n",
      "Epoch 32/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9557 - loss: 0.1341 - val_accuracy: 0.7949 - val_loss: 0.5303\n",
      "Epoch 33/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9704 - loss: 0.1058 - val_accuracy: 0.8013 - val_loss: 0.5051\n",
      "Epoch 34/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0891 - val_accuracy: 0.7885 - val_loss: 0.5308\n",
      "Epoch 35/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0850 - val_accuracy: 0.7821 - val_loss: 0.5477\n",
      "Epoch 36/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.1024 - val_accuracy: 0.8013 - val_loss: 0.5186\n",
      "Epoch 37/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.0961 - val_accuracy: 0.7949 - val_loss: 0.5236\n",
      "Epoch 38/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9589 - loss: 0.1021 - val_accuracy: 0.7949 - val_loss: 0.5388\n",
      "Epoch 39/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9778 - loss: 0.0915 - val_accuracy: 0.7949 - val_loss: 0.5064\n",
      "Epoch 40/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0694 - val_accuracy: 0.7885 - val_loss: 0.5567\n",
      "Epoch 41/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0774 - val_accuracy: 0.8141 - val_loss: 0.4788\n",
      "Epoch 42/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.0704 - val_accuracy: 0.8077 - val_loss: 0.4745\n",
      "Epoch 43/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9783 - loss: 0.0825 - val_accuracy: 0.8526 - val_loss: 0.4363\n",
      "Epoch 44/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0580 - val_accuracy: 0.8141 - val_loss: 0.4793\n",
      "Epoch 45/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0474 - val_accuracy: 0.8141 - val_loss: 0.4623\n",
      "Epoch 46/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9795 - loss: 0.0605 - val_accuracy: 0.8526 - val_loss: 0.4319\n",
      "Epoch 47/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9790 - loss: 0.0612 - val_accuracy: 0.8590 - val_loss: 0.4317\n",
      "Epoch 48/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.0585 - val_accuracy: 0.8462 - val_loss: 0.4384\n",
      "Epoch 49/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0471 - val_accuracy: 0.8462 - val_loss: 0.4415\n",
      "Epoch 50/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0443 - val_accuracy: 0.8205 - val_loss: 0.4671\n",
      "Epoch 51/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9849 - loss: 0.0537 - val_accuracy: 0.8141 - val_loss: 0.4657\n",
      "Epoch 52/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0385 - val_accuracy: 0.8077 - val_loss: 0.4866\n",
      "Epoch 53/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0554 - val_accuracy: 0.8590 - val_loss: 0.4319\n",
      "Epoch 54/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0453 - val_accuracy: 0.8333 - val_loss: 0.4579\n",
      "Epoch 55/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0361 - val_accuracy: 0.8333 - val_loss: 0.4652\n",
      "Epoch 56/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0349 - val_accuracy: 0.8141 - val_loss: 0.5148\n",
      "Epoch 57/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0259 - val_accuracy: 0.8397 - val_loss: 0.4499\n",
      "Epoch 58/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0313 - val_accuracy: 0.8462 - val_loss: 0.4430\n",
      "Epoch 59/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0259 - val_accuracy: 0.8462 - val_loss: 0.4410\n",
      "Epoch 60/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.0433 - val_accuracy: 0.8462 - val_loss: 0.4640\n",
      "Epoch 61/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0322 - val_accuracy: 0.8397 - val_loss: 0.4497\n",
      "Epoch 62/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0295 - val_accuracy: 0.8397 - val_loss: 0.4796\n",
      "Epoch 63/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0251 - val_accuracy: 0.8526 - val_loss: 0.4384\n",
      "Epoch 64/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0224 - val_accuracy: 0.8654 - val_loss: 0.4342\n",
      "Epoch 65/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0208 - val_accuracy: 0.8590 - val_loss: 0.4567\n",
      "Epoch 66/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0234 - val_accuracy: 0.8718 - val_loss: 0.4554\n",
      "Epoch 67/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9915 - loss: 0.0319 - val_accuracy: 0.8462 - val_loss: 0.4531\n",
      "Epoch 68/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0220 - val_accuracy: 0.8397 - val_loss: 0.4624\n",
      "Epoch 69/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0204 - val_accuracy: 0.8654 - val_loss: 0.4396\n",
      "Epoch 70/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0335 - val_accuracy: 0.8718 - val_loss: 0.4174\n",
      "Epoch 71/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0283 - val_accuracy: 0.8526 - val_loss: 0.4622\n",
      "Epoch 72/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0211 - val_accuracy: 0.8590 - val_loss: 0.4487\n",
      "Epoch 73/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0169 - val_accuracy: 0.8782 - val_loss: 0.4165\n",
      "Epoch 74/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0222 - val_accuracy: 0.8782 - val_loss: 0.4277\n",
      "Epoch 75/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0260 - val_accuracy: 0.8846 - val_loss: 0.4105\n",
      "Epoch 76/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0149 - val_accuracy: 0.8846 - val_loss: 0.3990\n",
      "Epoch 77/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0180 - val_accuracy: 0.8782 - val_loss: 0.4250\n",
      "Epoch 78/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0198 - val_accuracy: 0.8910 - val_loss: 0.4320\n",
      "Epoch 79/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.8782 - val_loss: 0.4231\n",
      "Epoch 80/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0257 - val_accuracy: 0.8654 - val_loss: 0.4515\n"
     ]
    }
   ],
   "source": [
    "history8 = model8.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133387af",
   "metadata": {},
   "source": [
    "**Simplify the networks**</br>\n",
    "Overfitting problems might be due to the complexity of the neural networks. Here only 2 conv2D layers are used, decreasing 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "352aeb23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def modelBuilder2L(X_train,\n",
    "                   f1,k1,a1,\n",
    "                   f2,k2,a2,                \n",
    "                   d1,dr1,da1,r1,\n",
    "                   d2,dr2,da2,r2,\n",
    "                   num):\n",
    "    '''\n",
    "    args:\n",
    "    \n",
    "    X_train: training data\n",
    "    f1,k1,a1: num of filters, filter size and activation func of 1st conv1D layer\n",
    "    f2,k2,a2: num of filters, filter size and activation func of 2nd conv1D layer\n",
    "    d1,dr1,da1, r1: num of units, dropout, activation func and regularizer para of 1st fully connected layer\n",
    "    d2,dr2,da2, r2: num of units, dropout, activation func and regularizer para  of 2nd fully connected layer\n",
    "    num: integer for distinguishing different model\n",
    "    \n",
    "    return:\n",
    "    model\n",
    "    '''\n",
    "    model = Sequential(name=\"Conv1D_\"+str(num))\n",
    "\n",
    "    m,n = X_train.shape\n",
    "    \n",
    "    #L1\n",
    "    model.add(Conv1D(filters = f1, kernel_size = k1, input_shape = (n,1), padding = 'same', activation = a1, name ='Conv1D_1'))\n",
    "    model.add(BatchNormalization(name = \"BN1\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling1\"))\n",
    "    #L2\n",
    "    model.add(Conv1D(filters = f2, kernel_size = k2, activation = a2, padding='same', name = \"Conv1D_2\"))\n",
    "    model.add(BatchNormalization(name = \"BN2\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling2\"))\n",
    "\n",
    "    #Flatten output\n",
    "    model.add(Flatten(name = \"Flatten\"))\n",
    "\n",
    "    #Fully connected layer 3\n",
    "    model.add(Dense(d1, activation = da1, name = \"Dense_1\"))\n",
    "    #Prevent overfitting\n",
    "    model.add(Dropout(dr1, name = \"Dropout_1\"))\n",
    "\n",
    "    #Fully connected layer 4 \n",
    "    model.add(Dense(d2, activation = da2, name = \"Dense_2\"))\n",
    "    #Prevent overfitting\n",
    "    model.add(Dropout(dr2, name = \"Dropout_2\"))\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(4, activation = 'softmax', name = \"Softmax\"))\n",
    "\n",
    "    #model compiling\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ea98757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Conv1D_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Conv1D_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">57,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m96\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m57,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,892</span> (273.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,892\u001b[0m (273.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,796</span> (272.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69,796\u001b[0m (272.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 9\n",
    "\n",
    "model9 = modelBuilder2L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a79257c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3940 - loss: 1.6729 - val_accuracy: 0.3462 - val_loss: 1.3712\n",
      "Epoch 2/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5416 - loss: 1.0141 - val_accuracy: 0.3269 - val_loss: 1.3670\n",
      "Epoch 3/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6486 - loss: 0.8510 - val_accuracy: 0.3333 - val_loss: 1.3580\n",
      "Epoch 4/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6612 - loss: 0.7695 - val_accuracy: 0.3333 - val_loss: 1.3427\n",
      "Epoch 5/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7016 - loss: 0.6969 - val_accuracy: 0.3333 - val_loss: 1.3228\n",
      "Epoch 6/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6940 - loss: 0.6736 - val_accuracy: 0.3397 - val_loss: 1.2911\n",
      "Epoch 7/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7497 - loss: 0.6214 - val_accuracy: 0.3397 - val_loss: 1.2399\n",
      "Epoch 8/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7560 - loss: 0.6078 - val_accuracy: 0.4038 - val_loss: 1.1524\n",
      "Epoch 9/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7938 - loss: 0.5014 - val_accuracy: 0.5064 - val_loss: 1.0458\n",
      "Epoch 10/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.4889 - val_accuracy: 0.5897 - val_loss: 0.9461\n",
      "Epoch 11/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8546 - loss: 0.3924 - val_accuracy: 0.6154 - val_loss: 0.8278\n",
      "Epoch 12/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8345 - loss: 0.4025 - val_accuracy: 0.6603 - val_loss: 0.7677\n",
      "Epoch 13/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.3936 - val_accuracy: 0.7051 - val_loss: 0.6864\n",
      "Epoch 14/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8905 - loss: 0.3136 - val_accuracy: 0.7244 - val_loss: 0.6139\n",
      "Epoch 15/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8855 - loss: 0.3263 - val_accuracy: 0.7564 - val_loss: 0.5671\n",
      "Epoch 16/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9217 - loss: 0.2809 - val_accuracy: 0.7500 - val_loss: 0.5534\n",
      "Epoch 17/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2608 - val_accuracy: 0.7821 - val_loss: 0.5105\n",
      "Epoch 18/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9032 - loss: 0.2536 - val_accuracy: 0.8013 - val_loss: 0.4760\n",
      "Epoch 19/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.2049 - val_accuracy: 0.7885 - val_loss: 0.4897\n",
      "Epoch 20/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9346 - loss: 0.2212 - val_accuracy: 0.7885 - val_loss: 0.4701\n",
      "Epoch 21/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9402 - loss: 0.1563 - val_accuracy: 0.8077 - val_loss: 0.4476\n",
      "Epoch 22/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.1849 - val_accuracy: 0.8269 - val_loss: 0.4216\n",
      "Epoch 23/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9406 - loss: 0.1701 - val_accuracy: 0.8462 - val_loss: 0.4073\n",
      "Epoch 24/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.2067 - val_accuracy: 0.8462 - val_loss: 0.3882\n",
      "Epoch 25/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.1552 - val_accuracy: 0.8269 - val_loss: 0.4108\n",
      "Epoch 26/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1496 - val_accuracy: 0.8333 - val_loss: 0.3985\n",
      "Epoch 27/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.1168 - val_accuracy: 0.8333 - val_loss: 0.3900\n",
      "Epoch 28/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9596 - loss: 0.1251 - val_accuracy: 0.8333 - val_loss: 0.3919\n",
      "Epoch 29/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.1278 - val_accuracy: 0.8269 - val_loss: 0.3850\n",
      "Epoch 30/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.0956 - val_accuracy: 0.8333 - val_loss: 0.3890\n",
      "Epoch 31/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0916 - val_accuracy: 0.8205 - val_loss: 0.4022\n",
      "Epoch 32/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.1189 - val_accuracy: 0.8333 - val_loss: 0.3889\n",
      "Epoch 33/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9647 - loss: 0.1128 - val_accuracy: 0.8526 - val_loss: 0.3415\n",
      "Epoch 34/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.1038 - val_accuracy: 0.8333 - val_loss: 0.3819\n",
      "Epoch 35/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9694 - loss: 0.0976 - val_accuracy: 0.8333 - val_loss: 0.3771\n",
      "Epoch 36/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0753 - val_accuracy: 0.8269 - val_loss: 0.3885\n",
      "Epoch 37/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0819 - val_accuracy: 0.8269 - val_loss: 0.3910\n",
      "Epoch 38/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0683 - val_accuracy: 0.8397 - val_loss: 0.3548\n",
      "Epoch 39/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0545 - val_accuracy: 0.8462 - val_loss: 0.3433\n",
      "Epoch 40/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9836 - loss: 0.0645 - val_accuracy: 0.8333 - val_loss: 0.3572\n",
      "Epoch 41/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.0617 - val_accuracy: 0.8333 - val_loss: 0.3605\n",
      "Epoch 42/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0516 - val_accuracy: 0.8397 - val_loss: 0.3448\n",
      "Epoch 43/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.0543 - val_accuracy: 0.8462 - val_loss: 0.3149\n",
      "Epoch 44/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0587 - val_accuracy: 0.8141 - val_loss: 0.3951\n",
      "Epoch 45/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0443 - val_accuracy: 0.8397 - val_loss: 0.3201\n",
      "Epoch 46/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.0470 - val_accuracy: 0.8526 - val_loss: 0.3322\n",
      "Epoch 47/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0564 - val_accuracy: 0.8333 - val_loss: 0.3415\n",
      "Epoch 48/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0488 - val_accuracy: 0.8333 - val_loss: 0.3299\n",
      "Epoch 49/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0437 - val_accuracy: 0.8077 - val_loss: 0.4005\n",
      "Epoch 50/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.0530 - val_accuracy: 0.8462 - val_loss: 0.3624\n",
      "Epoch 51/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0313 - val_accuracy: 0.8333 - val_loss: 0.3600\n",
      "Epoch 52/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0409 - val_accuracy: 0.8526 - val_loss: 0.3169\n",
      "Epoch 53/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0257 - val_accuracy: 0.8590 - val_loss: 0.3045\n",
      "Epoch 54/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0251 - val_accuracy: 0.8590 - val_loss: 0.3141\n",
      "Epoch 55/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0319 - val_accuracy: 0.8397 - val_loss: 0.3264\n",
      "Epoch 56/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0320 - val_accuracy: 0.8397 - val_loss: 0.3203\n",
      "Epoch 57/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0340 - val_accuracy: 0.8526 - val_loss: 0.3291\n",
      "Epoch 58/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0323 - val_accuracy: 0.8526 - val_loss: 0.3381\n",
      "Epoch 59/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0285 - val_accuracy: 0.8397 - val_loss: 0.3361\n",
      "Epoch 60/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0207 - val_accuracy: 0.8397 - val_loss: 0.3431\n",
      "Epoch 61/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.0374 - val_accuracy: 0.8590 - val_loss: 0.3088\n",
      "Epoch 62/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0306 - val_accuracy: 0.8590 - val_loss: 0.3051\n",
      "Epoch 63/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0237 - val_accuracy: 0.8462 - val_loss: 0.3183\n",
      "Epoch 64/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0250 - val_accuracy: 0.8590 - val_loss: 0.3216\n",
      "Epoch 65/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0253 - val_accuracy: 0.8654 - val_loss: 0.3038\n",
      "Epoch 66/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0324 - val_accuracy: 0.8526 - val_loss: 0.3180\n",
      "Epoch 67/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0388 - val_accuracy: 0.8462 - val_loss: 0.3485\n",
      "Epoch 68/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0168 - val_accuracy: 0.8718 - val_loss: 0.3270\n",
      "Epoch 69/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0230 - val_accuracy: 0.8590 - val_loss: 0.3264\n",
      "Epoch 70/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0170 - val_accuracy: 0.8654 - val_loss: 0.3419\n",
      "Epoch 71/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0233 - val_accuracy: 0.8590 - val_loss: 0.3403\n",
      "Epoch 72/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0148 - val_accuracy: 0.8397 - val_loss: 0.3606\n",
      "Epoch 73/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0139 - val_accuracy: 0.8654 - val_loss: 0.3005\n",
      "Epoch 74/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0126 - val_accuracy: 0.8526 - val_loss: 0.3362\n",
      "Epoch 75/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0231 - val_accuracy: 0.8526 - val_loss: 0.3397\n",
      "Epoch 76/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0145 - val_accuracy: 0.8397 - val_loss: 0.3962\n",
      "Epoch 77/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0175 - val_accuracy: 0.8397 - val_loss: 0.4197\n",
      "Epoch 78/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.8590 - val_loss: 0.3860\n",
      "Epoch 79/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.8654 - val_loss: 0.4027\n",
      "Epoch 80/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0106 - val_accuracy: 0.8590 - val_loss: 0.3701\n"
     ]
    }
   ],
   "source": [
    "history9 = model9.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74296e6",
   "metadata": {},
   "source": [
    "Simplifying the layer leads to the underfitting of the model, which lowers the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2ffb932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Conv1D_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Conv1D_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1D_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m14,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,396</span> (67.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,396\u001b[0m (67.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,348</span> (67.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,348\u001b[0m (67.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> (192.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m48\u001b[0m (192.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1,k1,a1 = 8,3,'relu'\n",
    "f2,k2,a2 = 16,5,'relu'\n",
    "d1,dr1,da1,r1 = 64,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 32,0.2,'relu',0.15\n",
    "num = 10\n",
    "\n",
    "model10 = modelBuilder2L(X1_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11db717a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3073 - loss: 1.8356 - val_accuracy: 0.4487 - val_loss: 1.3436\n",
      "Epoch 2/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3633 - loss: 1.3734 - val_accuracy: 0.4808 - val_loss: 1.3253\n",
      "Epoch 3/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4606 - loss: 1.1515 - val_accuracy: 0.4615 - val_loss: 1.2988\n",
      "Epoch 4/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4494 - loss: 1.1376 - val_accuracy: 0.4679 - val_loss: 1.2651\n",
      "Epoch 5/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4740 - loss: 1.0774 - val_accuracy: 0.4808 - val_loss: 1.2275\n",
      "Epoch 6/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5697 - loss: 0.9666 - val_accuracy: 0.4936 - val_loss: 1.1811\n",
      "Epoch 7/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5791 - loss: 0.8890 - val_accuracy: 0.5128 - val_loss: 1.1240\n",
      "Epoch 8/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6057 - loss: 0.8850 - val_accuracy: 0.5192 - val_loss: 1.0636\n",
      "Epoch 9/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6391 - loss: 0.8013 - val_accuracy: 0.5385 - val_loss: 1.0059\n",
      "Epoch 10/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6377 - loss: 0.8104 - val_accuracy: 0.5769 - val_loss: 0.9455\n",
      "Epoch 11/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6350 - loss: 0.7978 - val_accuracy: 0.5897 - val_loss: 0.8795\n",
      "Epoch 12/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6594 - loss: 0.7495 - val_accuracy: 0.6090 - val_loss: 0.8288\n",
      "Epoch 13/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6682 - loss: 0.7143 - val_accuracy: 0.6410 - val_loss: 0.7810\n",
      "Epoch 14/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6772 - loss: 0.7117 - val_accuracy: 0.6474 - val_loss: 0.7599\n",
      "Epoch 15/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7252 - loss: 0.6356 - val_accuracy: 0.6603 - val_loss: 0.7200\n",
      "Epoch 16/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7367 - loss: 0.6084 - val_accuracy: 0.6731 - val_loss: 0.6914\n",
      "Epoch 17/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7826 - loss: 0.5671 - val_accuracy: 0.7051 - val_loss: 0.6782\n",
      "Epoch 18/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7481 - loss: 0.5882 - val_accuracy: 0.7115 - val_loss: 0.6595\n",
      "Epoch 19/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7692 - loss: 0.5526 - val_accuracy: 0.7179 - val_loss: 0.6512\n",
      "Epoch 20/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7700 - loss: 0.5807 - val_accuracy: 0.7179 - val_loss: 0.6165\n",
      "Epoch 21/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7832 - loss: 0.4981 - val_accuracy: 0.7500 - val_loss: 0.5911\n",
      "Epoch 22/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7962 - loss: 0.4961 - val_accuracy: 0.7564 - val_loss: 0.5840\n",
      "Epoch 23/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.4434 - val_accuracy: 0.7692 - val_loss: 0.5848\n",
      "Epoch 24/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8110 - loss: 0.4429 - val_accuracy: 0.7692 - val_loss: 0.5560\n",
      "Epoch 25/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8075 - loss: 0.4538 - val_accuracy: 0.7692 - val_loss: 0.5593\n",
      "Epoch 26/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8225 - loss: 0.4390 - val_accuracy: 0.7628 - val_loss: 0.5389\n",
      "Epoch 27/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.4608 - val_accuracy: 0.7692 - val_loss: 0.5325\n",
      "Epoch 28/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 0.3845 - val_accuracy: 0.7692 - val_loss: 0.5344\n",
      "Epoch 29/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8578 - loss: 0.3480 - val_accuracy: 0.7885 - val_loss: 0.5191\n",
      "Epoch 30/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8527 - loss: 0.4003 - val_accuracy: 0.7756 - val_loss: 0.4948\n",
      "Epoch 31/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.3298 - val_accuracy: 0.7756 - val_loss: 0.5011\n",
      "Epoch 32/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.3318 - val_accuracy: 0.7756 - val_loss: 0.4854\n",
      "Epoch 33/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8809 - loss: 0.3259 - val_accuracy: 0.7756 - val_loss: 0.4864\n",
      "Epoch 34/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8644 - loss: 0.3266 - val_accuracy: 0.7885 - val_loss: 0.4540\n",
      "Epoch 35/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.3367 - val_accuracy: 0.7885 - val_loss: 0.4609\n",
      "Epoch 36/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8602 - loss: 0.3571 - val_accuracy: 0.8013 - val_loss: 0.4516\n",
      "Epoch 37/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8674 - loss: 0.3263 - val_accuracy: 0.8013 - val_loss: 0.4327\n",
      "Epoch 38/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 0.3125 - val_accuracy: 0.8141 - val_loss: 0.4289\n",
      "Epoch 39/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8823 - loss: 0.2685 - val_accuracy: 0.8141 - val_loss: 0.4207\n",
      "Epoch 40/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2524 - val_accuracy: 0.8077 - val_loss: 0.4311\n",
      "Epoch 41/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8841 - loss: 0.3174 - val_accuracy: 0.8333 - val_loss: 0.3949\n",
      "Epoch 42/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8985 - loss: 0.2600 - val_accuracy: 0.8333 - val_loss: 0.3986\n",
      "Epoch 43/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.2513 - val_accuracy: 0.8141 - val_loss: 0.3943\n",
      "Epoch 44/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9247 - loss: 0.2287 - val_accuracy: 0.8205 - val_loss: 0.3746\n",
      "Epoch 45/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8813 - loss: 0.2505 - val_accuracy: 0.8077 - val_loss: 0.3851\n",
      "Epoch 46/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9416 - loss: 0.2004 - val_accuracy: 0.8077 - val_loss: 0.3848\n",
      "Epoch 47/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.2194 - val_accuracy: 0.8013 - val_loss: 0.3811\n",
      "Epoch 48/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.2217 - val_accuracy: 0.8141 - val_loss: 0.3597\n",
      "Epoch 49/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.2130 - val_accuracy: 0.8205 - val_loss: 0.3525\n",
      "Epoch 50/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.1974 - val_accuracy: 0.8590 - val_loss: 0.3287\n",
      "Epoch 51/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2365 - val_accuracy: 0.8269 - val_loss: 0.3566\n",
      "Epoch 52/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.2166 - val_accuracy: 0.8333 - val_loss: 0.3419\n",
      "Epoch 53/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.1671 - val_accuracy: 0.8526 - val_loss: 0.3226\n",
      "Epoch 54/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.1756 - val_accuracy: 0.8526 - val_loss: 0.3205\n",
      "Epoch 55/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9254 - loss: 0.1901 - val_accuracy: 0.8590 - val_loss: 0.3187\n",
      "Epoch 56/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1519 - val_accuracy: 0.8397 - val_loss: 0.3349\n",
      "Epoch 57/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.1645 - val_accuracy: 0.8397 - val_loss: 0.3403\n",
      "Epoch 58/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9211 - loss: 0.1831 - val_accuracy: 0.8462 - val_loss: 0.3252\n",
      "Epoch 59/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1248 - val_accuracy: 0.8397 - val_loss: 0.3255\n",
      "Epoch 60/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.1697 - val_accuracy: 0.8654 - val_loss: 0.3142\n",
      "Epoch 61/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1431 - val_accuracy: 0.8654 - val_loss: 0.3075\n",
      "Epoch 62/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1460 - val_accuracy: 0.8782 - val_loss: 0.2961\n",
      "Epoch 63/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.1252 - val_accuracy: 0.8526 - val_loss: 0.3187\n",
      "Epoch 64/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9570 - loss: 0.1340 - val_accuracy: 0.8462 - val_loss: 0.3221\n",
      "Epoch 65/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1386 - val_accuracy: 0.8782 - val_loss: 0.2911\n",
      "Epoch 66/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.1192 - val_accuracy: 0.8782 - val_loss: 0.2800\n",
      "Epoch 67/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9448 - loss: 0.1352 - val_accuracy: 0.8590 - val_loss: 0.3045\n",
      "Epoch 68/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9662 - loss: 0.1104 - val_accuracy: 0.8718 - val_loss: 0.2788\n",
      "Epoch 69/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1317 - val_accuracy: 0.8782 - val_loss: 0.2788\n",
      "Epoch 70/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1075 - val_accuracy: 0.8718 - val_loss: 0.2831\n",
      "Epoch 71/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.1361 - val_accuracy: 0.8654 - val_loss: 0.3023\n",
      "Epoch 72/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1138 - val_accuracy: 0.8718 - val_loss: 0.2815\n",
      "Epoch 73/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9549 - loss: 0.0971 - val_accuracy: 0.8782 - val_loss: 0.2837\n",
      "Epoch 74/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1075 - val_accuracy: 0.8718 - val_loss: 0.3005\n",
      "Epoch 75/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9529 - loss: 0.1276 - val_accuracy: 0.8910 - val_loss: 0.2578\n",
      "Epoch 76/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1063 - val_accuracy: 0.8910 - val_loss: 0.2567\n",
      "Epoch 77/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9435 - loss: 0.1135 - val_accuracy: 0.8718 - val_loss: 0.2794\n",
      "Epoch 78/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9771 - loss: 0.0906 - val_accuracy: 0.8846 - val_loss: 0.2655\n",
      "Epoch 79/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.0796 - val_accuracy: 0.9167 - val_loss: 0.2393\n",
      "Epoch 80/80\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0828 - val_accuracy: 0.9103 - val_loss: 0.2540\n"
     ]
    }
   ],
   "source": [
    "history10 = model10.fit(X1_train_scaled, y1_train, \n",
    "                      validation_data=(X1_val_scaled, y1_val), \n",
    "                      batch_size=16, \n",
    "                      epochs=80)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7010ec1e",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "### 4.1 Model Evaluation For Dataset1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17665928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train and Validation accuracy and loss\n",
    "f = plt.figure(figsize = (12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('train validation accuracy')\n",
    "plt.plot(history9.history['accuracy'])\n",
    "plt.plot(history9.history['val_accuracy'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('train validation loss')\n",
    "plt.plot(history9.history['loss'])\n",
    "plt.plot(history9.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4aeb3bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "y_prob = model1.predict(X1_test_scaled)\n",
    "y_pred = np.argmax(y_prob, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61f7d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acc_1d = round(accuracy_score(y_pred,y1_test),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01118636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66767ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_1d = confusion_matrix(y1_test,y_pred)\n",
    "cm_display_1d = ConfusionMatrixDisplay(confusion_matrix = cm_1d, display_labels = ['Happy', 'Relaxed', 'Sad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9dac2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.97      0.86      0.91        65\n",
      "     Relaxed       0.74      0.95      0.83        65\n",
      "         Sad       0.98      0.80      0.88        65\n",
      "\n",
      "    accuracy                           0.87       195\n",
      "   macro avg       0.89      0.87      0.87       195\n",
      "weighted avg       0.89      0.87      0.87       195\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(y1_test, y_pred, target_names = ['Happy', 'Relaxed', 'Sad']))\n",
    "cm_display_1d.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
